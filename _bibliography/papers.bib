
@inproceedings{louiset_separating_2024,
	title = {Separating common from salient patterns with {Contrastive} {Representation} {Learning}},
	booktitle = {International {Conference} on {Learning} {Representations} ({ICLR})},
	author = {Louiset, Robin and Duchesnay, Edouard and Grigis, Antoine and Gori, Pietro},
	year = {2024},
	abbr = {ICLR},
	abstract={Contrastive Analysis is a sub-field of Representation Learning that aims at separating common factors of variation between two datasets, a background (i.e., healthy subjects) and a target (i.e., diseased subjects), from the salient factors of variation, only present in the target dataset. Despite their relevance, current models based on Variational Auto-Encoders have shown poor performance in learning semantically-expressive representations. On the other hand, Contrastive Representation Learning has shown tremendous performance leaps in various applications (classification, clustering, etc.). In this work, we propose to leverage the ability of Contrastive Learning to learn semantically expressive representations well adapted for Contrastive Analysis. We reformulate it under the lens of the InfoMax Principle and identify two Mutual Information terms to maximize and one to minimize. We decompose the first two terms into an Alignment and a Uniformity term, as commonly done in Contrastive Learning. Then, we motivate a novel Mutual Information minimization strategy to prevent information leakage between common and salient distributions. We validate our method, called SepCLR, on three visual datasets and three medical datasets, specifically conceived to assess the pattern separation capability in Contrastive Analysis.},
	url={https://arxiv.org/pdf/2402.11928},
	code={https://github.com/neurospin-projects/2024_rlouiset_sep_clr}
}



@inproceedings{sarfati_guiding_2025,
	title = {Guiding the classification of hepatocellular carcinoma on 3D {CT}-scans using deep and handcrafted radiological features},
	url = {http://arxiv.org/abs/2501.08097},
	abstract = {Hepatocellular carcinoma is the most spread primary liver cancer across the world. The gold standard for {HCC} diagnosis is liver biopsy. However, in the clinical routine, expert radiologists provide a visual diagnosis by interpreting hepatic {CT}-scans according to a standardized protocol, the {LI}-{RADS}, which uses five radiological criteria with an associated decision tree. In this paper, we propose an automatic approach to predict histology-proven {HCC} from {CT} images in order to reduce radiologists' inter-variability. We first show that standard deep learning methods fail to accurately predict {HCC} from {CT}-scans on a challenging database, and propose a two-step approach inspired by the {LI}-{RADS} system to improve the performance. We achieve improvements from 6 to 18 points of {AUC} with respect to deep learning baselines trained with different architectures. We also provide clinical validation of our method, achieving results that outperform non-expert radiologists and are on par with expert ones.},
	booktitle = {{IEEE} International Symposium on Biomedical Imaging ({ISBI})},
	author = {Sarfati, E. and Bone, A. and Rohe, M.-M. and Aube, C. and Ronot, M. and Gori, Pietro and Bloch, I.},
	year = {2025},
	abbr={IEEE ISBI}
}


@article{louiset_automatic_2024,
	title = {Automatic Discovery of Disease Subgroups by Contrasting with Healthy Controls.},
	journal = {Under Review},
	author = {Louiset, Robin and Duchesnay, Eduouard and Dufumier, Benoit and Grigis, Antoine and Gori, Pietro},
	year = {2024},
	abbr = {Under Review}
}


@inproceedings{carton_double_2024,
	title = {Double {InfoGAN} for {Contrastive} {Analysis}},
	abstract = {Contrastive Analysis (CA) deals with the discovery of what is common and what is distinctive of a target domain compared to a background one. This is of great interest in many applications, such as medical imaging. Current state-of-the-art (SOTA) methods are latent variable models based on VAE (CAVAEs). However, they all either ignore important constraints or they don‚Äôt enforce fundamental assumptions. This may lead to suboptimal solutions where distinctive factors are mistaken for common ones (or viceversa). Furthermore, the generated images have a rather poor quality, typical of VAEs, decreasing their interpretability and usefulness. Here, we propose Double InfoGAN, the first GAN based method for CA that leverages the high-quality synthesis of GAN and the separation power of InfoGAN. Experimental results on four visual datasets, from simple synthetic examples to complex medical images, show that the proposed method outperforms SOTA CA-VAEs in terms of latent separation and image quality. Datasets and code are available online1.},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics} ({AISTATS})},
	author = {Carton, Florence and Louiset, Robin and Gori, Pietro},
	year = {2024},
	abbr = {AISTATS},
	url={https://proceedings.mlr.press/v238/carton24a.html},
	code={https://github.com/Florence-C/Double_InfoGAN}
}

@article{la_barbera_tubular_2023,
	title = {Tubular structures segmentation of pediatric abdominal-visceral {ceCT} images with renal tumors: {Assessment}, comparison and improvement},
	volume = {90},
	journal = {Medical Image Analysis},
	author = {La Barbera, Giammarco and Rouet, Laurence and Boussaid, Haithem and Lubet, Alexis and Kassir, Rani and Sarnacki, Sabine and Gori, Pietro and Bloch, Isabelle},
	year = {2023},
	pages = {102986},
	abbr = {MedIA},
	url={https://www.sciencedirect.com/science/article/pii/S1361841523002463},
	code={https://github.com/Giammarco07/DeePRAC_project},
	abstract={Renal tubular structures, such as ureters, arteries and veins, are very important for building a complete digital 3D anatomical model of a patient. However, they can be challenging to segment from ceCT images due to their elongated shape, diameter variation and intra- and inter-patient contrast heterogeneity. This task is even more difficult in pediatric and pathological subjects, due to high inter-subject anatomical variations, potential presence of tumors, small volume of these structures compared to the surrounding, and small available labeled datasets.
Given the limited literature on methods dedicated to children, and in order to find inspirational approaches, a complete assessment of state-of-the-art methods for the segmentation of renal tubular structures on ceCT images on adults is presented. Then, these methods are tested and compared on a private pediatric and pathological dataset of 79 abdominal-visceral ceCT images with arteriovenous phase acquisitions. To the best of our knowledge, both assessment and comparison in this specific case are novel.
Eventually, we also propose a new loss function which leverages for the first time the use of vesselness functions on the predicted segmentation. We show that the combination of this loss function with state-of-the-art methods improves the topological coherence of the segmented tubular structures.}
}

@inproceedings{sarfati_weakly-supervised_2023,
	title = {Weakly-supervised positional contrastive learning: application to cirrhosis classification},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} - {MICCAI}},
	author = {Sarfati, Emma and B√¥ne, Alexandre and Roh√©, Marc-Michel and Gori, Pietro and Bloch, Isabelle},
	year = {2023},
	abbr = {MICCAI},
	url={https://link.springer.com/chapter/10.1007/978-3-031-43907-0_22},
	code={https://github.com/Guerbet-AI/wsp-contrastive},
	abstract={Large medical imaging datasets can be cheaply and quickly annotated with low-confidence, weak labels (e.g., radiological scores). Access to high-confidence labels, such as histology-based diagnoses, is rare and costly. Pretraining strategies, like contrastive learning (CL) methods, can leverage unlabeled or weakly-annotated datasets. These methods typically require large batch sizes, which poses a difficulty in the case of large 3D images at full resolution, due to limited GPU memory. Nevertheless, volumetric positional information about the spatial context of each 2D slice can be very important for some medical applications. In this work, we propose an efficient weakly-supervised positional (WSP) contrastive learning strategy where we integrate both the spatial context of each 2D slice and a weak label via a generic kernel-based loss function. We illustrate our method on cirrhosis prediction using a large volume of weakly-labeled images, namely radiological low-confidence annotations, and small strongly-labeled (i.e., high-confidence) datasets. The proposed model improves the classification AUC by 5% with respect to a baseline model on our internal dataset, and by 26% on the public LIHC dataset from the Cancer Genome Atlas.}
}

@inproceedings{dufumier_contrastive_2021,
	title = {Contrastive {Learning} with {Continuous} {Proxy} {Meta}-data for {3D} {MRI} {Classification}},
	abstract = {Traditional supervised learning with deep neural networks requires a tremendous amount of labelled data to converge to a good solution. For 3D medical images, it is often impractical to build a large homogeneous annotated dataset for a specific pathology. Self-supervised methods offer a new way to learn a representation of the images in an unsupervised manner with a neural network. In particular, contrastive learning has shown great promises by (almost) matching the performance of fully-supervised CNN on vision tasks. Nonetheless, this method does not take advantage of available meta-data, such as participant‚Äôs age, viewed as prior knowledge. Here, we propose to leverage continuous proxy metadata, in the contrastive learning framework, by introducing a new loss called y-Aware InfoNCE loss. Specifically, we improve the positive sampling during pre-training by adding more positive examples with similar proxy meta-data with the anchor, assuming they share similar discriminative semantic features.¬†With our method, a 3D CNN model pre-trained on \$\$10{\textasciicircum}4\$\$104multi-site healthy brain MRI scans can extract relevant features for three classification tasks: schizophrenia, bipolar diagnosis and Alzheimer‚Äôs detection. When fine-tuned, it also outperforms 3D CNN trained from scratch on these tasks, as well as state-of-the-art self-supervised methods. Our code is made publicly available here.},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} - {MICCAI}},
	author = {Dufumier, Benoit and Gori, Pietro and Victor, Julie and Grigis, Antoine and Duchesnay, Edouard},
	year = {2021},
	abbr = {MICCAI},
	url={https://link.springer.com/chapter/10.1007/978-3-030-87196-3_6},
	code={https://github.com/Duplums/yAwareContrastiveLearning}
}

@inproceedings{dufumier_conditional_2021,
	title = {Conditional {Alignment} and {Uniformity} for {Contrastive} {Learning} with {Continuous} {Proxy} {Labels}},
	abstract = {Contrastive Learning has shown impressive results on natural and medical images, without requiring annotated data. However, a particularity of medical images is the availability of meta-data (such as age or sex) that can be exploited for learning representations. Here, we show that the recently proposed contrastive y-Aware InfoNCE loss, that integrates multi-dimensional meta-data, asymptotically optimizes two properties: conditional alignment and global uniformity. Similarly to [Wang, 2020], conditional alignment means that similar samples should have similar features, but conditionally on the meta-data. Instead, global uniformity means that the (normalized) features should be uniformly distributed on the unit hyper-sphere, independently of the meta-data. Here, we propose to define conditional uniformity, relying on the meta-data, that repel only samples with dissimilar meta-data. We show that direct optimization of both conditional alignment and uniformity improves the representations, in terms of linear evaluation, on both CIFAR-100 and a brain MRI dataset.},
	booktitle = {{MedNeurIPS}, {Workshop} {NeurIPS}},
	author = {Dufumier, Benoit and Gori, Pietro and Victor, Julie and Grigis, Antoine and Duchesnay, Edouard},
	year = {2021},
	abbr = {MedNeurIPS},
	url={https://nips.cc/virtual/2021/36825}
}

@inproceedings{ruppli_decoupled_2023,
	title = {Decoupled conditional contrastive learning with variable metadata for prostate lesion detection},
	booktitle = {{MILLanD} workshop ({MICCAI})},
	author = {Ruppli, Camille and Gori, Pietro and Ardon, Roberto and Bloch, Isabelle},
	year = {2023},
	abbr = {MICCAI-W},
	url={https://link.springer.com/chapter/10.1007/978-3-031-44917-8_9},
	code={https://github.com/camilleruppli/decoupled_ccl}
}

@inproceedings{vetil_non-redundant_2023,
	title = {Non-{Redundant} {Combination} of {Hand}-{Crafted} and {Deep} {Learning} {Radiomics}: {Application} to the {Early} {Detection} of {Pancreatic} {Cancer}},
	booktitle = {{CaPTion} workshop ({MICCAI})},
	author = {V√©til, Rebeca and Abi-Nader, Cl√©ment and B√¥ne, Alexandre and Vullierme, Marie-Pierre and Roh√©, Marc-Michel and Gori, Pietro and Bloch, Isabelle},
	year = {2023},
	abbr = {MICCAI-W},
	url={https://link.springer.com/chapter/10.1007/978-3-031-45350-2_6}
}

@inproceedings{louiset_sepvae_2024,
	title = {{SepVAE}: a contrastive {VAE} to separate pathological patterns from healthy ones},
	booktitle = {Medical {Imaging} with {Deep} {Learning} ({MIDL})},
	author = {Louiset, Robin and Duchesnay, Edouard and Grigis, Antoine and Dufumier, Benoit and Gori, Pietro},
	year = {2024},
	abbr = {MIDL},
	url={https://arxiv.org/pdf/2307.06206},
	code={https://github.com/neurospin-projects/2023_rlouiset_sepvae},
	abstract={Contrastive Analysis VAEs (CA-VAEs) are a family of Variational auto-encoders (VAEs) that aims at separating the common factors of variation between a background dataset (BG) (i.e., healthy subjects) and a target dataset (TG) (i.e., patients) from the ones that only exist in the target dataset. To do so, these methods separate the latent space into a set of salient features (i.e., proper to the target dataset) and a set of common features (i.e., exist in both datasets). Currently, all models fail to prevent the sharing of information between latent spaces effectively and to capture all salient factors of variation. To this end, we introduce two crucial regularization losses: a disentangling term between common and salient representations and a classification term between background and target samples in the salient space. We show a better performance than previous CA-VAEs methods on three medical applications and a natural images dataset (CelebA).}
}

@inproceedings{ingeman-nielsen_t_surface_2012,
	title = {Surface {Geophysical} {Measurements} for {Locating} and {Mapping} {Ice}-{Wedges}},
	url = {http://ascelibrary.org/doi/abs/10.1061/9780784412473.063},
	doi = {10.1061/9780784412473.063},
	booktitle = {Cold {Regions} {Engineering}},
	author = {{Ingeman-Nielsen T.} and {Toma≈°koviƒço v√° S.} and {Larsen S. H.} and {Apar√≠cio S. F.} and Gori, Pietro},
	year = {2012},
	abbr = {CRE}
}

@inproceedings{olivetti_nonlinear_2020,
	title = {Nonlinear {Alignment} of {Whole} {Tractograms} with the {Linear} {Assignment}¬†{Problem}},
	doi = {10.1007/978-3-030-50120-4_1},
	abstract = {After registration of the imaging data of two brains, homologous anatomical structures are expected to overlap better than before registration. Diffusion magnetic resonance imaging (dMRI) techniques and tractography techniques provide a representation of the anatomical connections in the white matter, as hundreds of thousands of streamlines, forming the tractogram. The literature on methods for aligning tractograms is in active development and provides methods that operate either from voxel information, e.g. fractional anisotropy, orientation distribution function, T1-weighted MRI, or directly from streamline information. In this work, we align streamlines using the linear assignment problem (LAP) and propose a method to reduce the high computational cost of aligning whole brain tractograms. As further contribution, we present a comparison among some of the freely-available linear and nonlinear tractogram alignment methods, where we show that our LAP-based method outperforms all others. In discussing the results, we show that a main limitation of all streamline-based nonlinear registration methods is the computational cost and that addressing such problem may lead to further improvement in the quality of registration.},
	booktitle = {Biomedical {Image} {Registration} ({WBIR})},
	author = {Olivetti, Emanuele and Gori, Pietro and Astolfi, Pietro and Bert√≥, Giulia and Avesani, Paolo},
	year = {2020},
	pages = {3--11},
	abbr = {WBIR},
	url={https://link.springer.com/chapter/10.1007/978-3-030-50120-4_1},
	code={https://github.com/FBK-NILab/WBIR2020_experiments}
}

@inproceedings{francois_weighted_2022,
	title = {Weighted {Metamorphosis} for¬†{Registration} of¬†{Images} with¬†{Different} {Topologies}},
	doi = {10.1007/978-3-031-11203-4_2},
	abstract = {We present an extension of the Metamorphosis algorithm to align images with different topologies and/or appearances. We propose to restrict/limit the metamorphic intensity additions using a time-varying spatial weight function. It can be used to model prior knowledge about the topological/appearance changes (e.g., tumour/oedema). We show that our method improves the disentanglement between anatomical (i.e., shape) and topological (i.e., appearance) changes, thus improving the registration interpretability and its clinical usefulness. As clinical application, we validated our method using MR brain tumour images from the BraTS 2021 dataset. We showed that our method can better align healthy brain templates to images with brain tumours than existing state-of-the-art methods. Our PyTorch code is freely available here: https://github.com/antonfrancois/Demeter\_metamorphosis.},
	booktitle = {Biomedical {Image} {Registration} ({WBIR})},
	author = {Fran√ßois, Anton and Maillard, Matthis and Oppenheim, Catherine and Pallud, Johan and Bloch, Isabelle and Gori, Pietro and Glaun√®s, Joan},
	year = {2022},
	pages = {8--17},
	abbr = {WBIR},
	url={https://link.springer.com/chapter/10.1007/978-3-031-11203-4_2},
	code={https://github.com/antonfrancois/Demeter_metamorphosis}
}

@inproceedings{kips_ca-gan_2020,
	title = {{CA}-{GAN}: {Weakly} {Supervised} {Color} {Aware} {GAN} for {Controllable} {Makeup} {Transfer}},
	doi = {10.1007/978-3-030-67070-2_17},
	abstract = {While existing makeup style transfer models perform an image synthesis whose results cannot be explicitly controlled, the ability to modify makeup color continuously is a desirable property for virtual try-on applications. We propose a new formulation for the makeup style transfer task, with the objective to learn a color controllable makeup style synthesis. We introduce CA-GAN, a generative model that learns to modify the color of specific objects (e.g. lips or eyes) in the image to an arbitrary target color while preserving background. Since color labels are rare and costly to acquire, our method leverages weakly supervised learning for conditional GANs. This enables to learn a controllable synthesis of complex objects, and only requires a weak proxy of the image attribute that we desire to modify. Finally, we present for the first time a quantitative analysis of makeup style transfer and color control performance.},
	booktitle = {{AIM20} ({ECCV} {Workshop})},
	author = {Kips, Robin and Gori, Pietro and Perrot, Matthieu and Bloch, Isabelle},
	year = {2020},
	pages = {280--296},
	abbr = {ECCV-W},
	url={https://robinkips.github.io/CA-GAN/}

}

@inproceedings{louiset_ucsl_2021,
	title = {{UCSL} : {A} {Machine} {Learning} {Expectation}-{Maximization} {Framework} for¬†{Unsupervised} {Clustering} {Driven} by¬†{Supervised} {Learning}},
	doi = {10.1007/978-3-030-86486-6_46},
	abstract = {Subtype Discovery consists in finding interpretable and consistent sub-parts of a dataset, which are also relevant to a certain supervised task. From a mathematical point of view, this can be defined as a clustering task driven by supervised learning in order to uncover subgroups in line with the supervised prediction. In this paper, we propose a general Expectation-Maximization ensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised Learning). Our method is generic, it can integrate any clustering method and can be driven by both binary classification and regression. We propose to construct a non-linear model by merging multiple linear estimators, one per cluster. Each hyperplane is estimated so that it correctly discriminates - or predict - only one cluster. We use SVC or Logistic Regression for classification and SVR for regression. Furthermore, to perform cluster analysis within a more suitable space, we also propose a dimension-reduction algorithm that projects the data onto an orthonormal space relevant to the supervised task. We analyze the robustness and generalization capability of our algorithm using synthetic and experimental datasets. In particular, we validate its ability to identify suitable consistent sub-types by conducting a psychiatric-diseases cluster analysis with known ground-truth labels. The gain of the proposed method over previous state-of-the-art techniques is about +1.9 points in terms of balanced accuracy. Finally, we make codes and examples available in a scikit-learn-compatible Python package. https://github.com/neurospin-projects/2021\_rlouiset\_ucsl/.},
	booktitle = {European {Conference} on {Machine} {Learning} and {Principles} and {Practice} of {Knowledge} {Discovery} in {Databases} ({ECML}/{PKDD})},
	author = {Louiset, Robin and Gori, Pietro and Dufumier, Benoit and Houenou, Josselin and Grigis, Antoine and Duchesnay, Edouard},
	year = {2021},
	abbr = {ECML/PKDD},
	url={https://link.springer.com/chapter/10.1007/978-3-030-86486-6_46},
	code={https://github.com/neurospin-projects/2021_rlouiset_ucsl}
}

@inproceedings{ingeman-nielsen_optimization_2012,
	title = {An {Optimization} {Algorithm} {For} {Interpreting} {Thermal} {Parameters} {For} {Frozen} {Soils} {With} {Significant} {Unfrozen} {Water} {Content}},
	volume = {4},
	abstract = {In this study we develop an optimization scheme for establishing thermal parameters of permafrost soils, based on heat pulse measurements. The method is applied to measurements on a sand sample and a clayey silt sample. Acceptable fits are obtained with porosity and freezing point constrained, and all other parameters free ‚Äì resulting in good reproduction of pulse amplitude and dispersion.},
	booktitle = {Tenth {International} {Conference} {On} {Permafrost}},
	author = {Ingeman-Nielsen, Thomas and Gori, Pietro and Tomaskovicova, Sonia},
	year = {2012},
	pages = {224--225},
	abbr={ICOP}
}

@inproceedings{gori_bayesian_2013,
	title = {Bayesian {Atlas} {Estimation} for the {Variability} {Analysis} of {Shape} {Complexes}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-40811-3_34},
	abstract = {In this paper we propose a Bayesian framework for multi-object atlas estimation based on the metric of currents which permits to deal with both curves and surfaces without relying on point correspondence. This approach aims to study brain morphometry as a whole and not as a set of different components, focusing mainly on the shape and relative position of different anatomical structures which is fundamental in neuro-anatomical studies. We propose a generic algorithm to estimate templates of sets of curves (fiber bundles) and closed surfaces (sub-cortical structures) which have the same ‚Äúform‚Äù (topology) of the shapes present in the population. This atlas construction method is based on a Bayesian framework which brings to two main improvements with respect to previous shape based methods. First, it allows to estimate from the data set a parameter specific to each object which was previously fixed by the user: the trade-off between data-term and regularity of deformations. In a multi-object analysis these parameters balance the contributions of the different objects and the need for an automatic estimation is even more crucial. Second, the covariance matrix of the deformation parameters is estimated during the atlas construction in a way which is less sensitive to the outliers of the population.},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} ‚Äì {MICCAI}},
	author = {Gori, Pietro and Colliot, Olivier and Worbe, Yulia and Marrakchi-Kacem, Linda and Lecomte, Sophie and Poupon, Cyril and Hartmann, Andreas and Ayache, Nicholas and Durrleman, Stanley},
	year = {2013},
	pages = {267--274},
	abbr = {MICCAI}
}

@inproceedings{gori_prototype_2014,
	title = {A {Prototype} {Representation} to {Approximate} {White} {Matter} {Bundles} with {Weighted} {Currents}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-10443-0_37},
	abstract = {Quantitative and qualitative analysis of white matter fibers resulting from tractography algorithms is made difficult by their huge number. To this end, we propose an approximation scheme which gives as result a more concise but at the same time exhaustive representation of a fiber bundle. It is based on a novel computational model for fibers, called weighted currents, characterised by a metric that considers both the pathway and the anatomical locations of the endpoints of the fibers. Similarity has therefore a twofold connotation: geometrical and related to the connectivity. The core idea is to use this metric for approximating a fiber bundle with a set of weighted prototypes, chosen among the fibers, which represent ensembles of similar fibers. The weights are related to the number of fibers represented by the prototypes. The algorithm is divided into two steps. First, the main modes of the fiber bundle are detected using a modularity based clustering algorithm. Second, a prototype fiber selection process is carried on in each cluster separately. This permits to explain the main patterns of the fiber bundle in a fast and accurate way.},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} ‚Äì {MICCAI}},
	author = {Gori, Pietro and Colliot, Olivier and Marrakchi-Kacem, Linda and Worbe, Yulia and Fallani, Fabrizio De Vico and Chavez, Mario and Lecomte, Sophie and Poupon, Cyril and Hartmann, Andreas and Ayache, Nicholas and Durrleman, Stanley},
	year = {2014},
	pages = {289--296},
	abbr = {MICCAI}
}

@inproceedings{routier_evaluation_2014,
	title = {Evaluation of morphometric descriptors of deep brain structures for the automatic classification of patients with {Alzheimer}‚Äôs disease, mild cognitive impairment and elderly controls},
	url = {https://hal.inria.fr/hal-01099081/},
	booktitle = {{MICCAI} {Workshop}},
	author = {Routier, Alexandre and Gori, Pietro and Fouquier, Ana B. Graciano and Lecomte, Sophie and Colliot, Olivier and Durrleman, Stanley},
	year = {2014},
	pages = {8},
	abbr = {MICCAI-W}
}

@inproceedings{gori_joint_2015,
	title = {Joint {Morphometry} of {Fiber} {Tracts} and {Gray} {Matter} {Structures} {Using} {Double} {Diffeomorphisms}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-19992-4_21},
	abstract = {This work proposes an atlas construction method to jointly analyse the relative position and shape of fiber tracts and gray matter structures. It is based on a double diffeomorphism which is a composition of two diffeomorphisms. The first diffeomorphism acts only on the white matter keeping fixed the gray matter of the atlas. The resulting white matter, together with the gray matter, are then deformed by the second diffeomorphism. The two diffeomorphisms are related and jointly optimised. In this way, the first diffeomorphisms explain the variability in structural connectivity within the population, namely both changes in the connected areas of the gray matter and in the geometry of the pathway of the tracts. The second diffeomorphisms put into correspondence the homologous anatomical structures across subjects. Fiber bundles are approximated with weighted prototypes using the metric of weighted currents. The atlas, the covariance matrix of deformation parameters and the noise variance of each structure are automatically estimated using a Bayesian approach. This method is applied to patients with Tourette syndrome and controls showing a variability in the structural connectivity of the left cortico-putamen circuit.},
	booktitle = {Information {Processing} in {Medical} {Imaging} ({IPMI})},
	author = {Gori, Pietro and Colliot, Olivier and Marrakchi-Kacem, Linda and Worbe, Yulia and Routier, Alexandre and Poupon, Cyril and Hartmann, Andreas and Ayache, Nicholas and Durrleman, Stanley},
	year = {2015},
	pages = {275--287},
	abbr = {IPMI}
}

@article{gori_parsimonious_2016,
	title = {Parsimonious {Approximation} of {Streamline} {Trajectories} in {White} {Matter} {Fiber} {Bundles}},
	volume = {35},
	doi = {10.1109/TMI.2016.2591080},
	abstract = {Fiber bundles stemming from tractography algorithms contain many streamlines. They require therefore a great amount of computer memory and computational resources to be stored, visualised and processed. We propose an approximation scheme for fiber bundles which results in a parsimonious representation of weighted prototypes. Prototypes are chosen among the streamlines and they represent groups of similar streamlines. Their weight is related to the number of approximated streamlines. Both streamlines and prototypes are modelled as weighted currents. This computational model does not need point-to-point correspondences and two streamlines are considered similar if their endpoints are close to each other and if their pathways follow similar trajectories. Moreover, the space of weighted currents is a vector space with a closed-form metric. This permits easy computation of the approximation error and the selection of the prototypes is based on the minimisation of this error. We propose an iterative algorithm which approximates independently and simultaneously all the fascicles of the bundle in a fast and accurate way. We show that the resulting representation preserves the shape of the bundle and it can be used to accurately reconstruct the original structural connectivity. We evaluate our algorithm on bundles obtained from both deterministic and probabilistic tractography algorithms. The resulting approximations use on average only 2\% of the original streamlines as prototypes. This drastically reduces the computational burden of the processes where the geometry of the streamlines is considered. We demonstrate its effectiveness using as example the registration between two fiber bundles.},
	number = {12},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Gori, Pietro and Colliot, Olivier and Marrakchi-Kacem, Linda and Worbe, Yulia and De Vico Fallani, Fabrizio and Chavez, Mario and Poupon, Cyril and Hartmann, Andreas and Ayache, Nicholas and Durrleman, Stanley},
	year = {2016},
	pages = {2609--2619},
	abbr = {IEEE TMI}
}

@article{gori_bayesian_2017,
	title = {A {Bayesian} framework for joint morphometry of surface and curve meshes in multi-object complexes},
	volume = {35},
	url = {http://www.sciencedirect.com/science/article/pii/S136184151630158X},
	doi = {10.1016/j.media.2016.08.011},
	abstract = {We present a Bayesian framework for atlas construction of multi-object shape complexes comprised of both surface and curve meshes. It is general and can be applied to any parametric deformation framework and to all shape models with which it is possible to define probability density functions (PDF). Here, both curve and surface meshes are modelled as Gaussian random varifolds, using a finite-dimensional approximation space on which PDFs can be defined. Using this framework, we can automatically estimate the parameters balancing data-terms and deformation regularity, which previously required user tuning. Moreover, it is also possible to estimate a well-conditioned covariance matrix of the deformation parameters. We also extend the proposed framework to data-sets with multiple group labels. Groups share the same template and their deformation parameters are modelled with different distributions. We can statistically compare the groups‚Äôdistributions since they are defined on the same space. We test our algorithm on 20 Gilles de la Tourette patients and 20 control subjects, using three sub-cortical regions and their incident white matter fiber bundles. We compare their morphological characteristics and variations using a single diffeomorphism in the ambient space. The proposed method will be integrated with the Deformetrica software package, publicly available at www.deformetrica.org.},
	journal = {Medical Image Analysis},
	author = {Gori, Pietro and Colliot, Olivier and Marrakchi-Kacem, Linda and Worbe, Yulia and Poupon, Cyril and Hartmann, Andreas and Ayache, Nicholas and Durrleman, Stanley},
	year = {2017},
	pages = {458--474},
	abbr = {MedIA}
}

@inproceedings{kumar_white_2017,
	title = {White {Matter} {Fiber} {Segmentation} {Using} {Functional} {Varifolds}},
	doi = {10.1007/978-3-319-67675-3_9},
	abstract = {The extraction of fibers from dMRI data typically produces a large number of fibers, it is common to group fibers into bundles. To this end, many specialized distance measures, such as MCP, have been used for fiber similarity. However, these distance based approaches require point-wise correspondence and focus only on the geometry of the fibers. Recent publications have highlighted that using microstructure measures along fibers improves tractography analysis. Also, many neurodegenerative diseases impacting white matter require the study of microstructure measures as well as the white matter geometry. Motivated by these, we propose to use a novel computational model for fibers, called functional varifolds, characterized by a metric that considers both the geometry and microstructure measure (e.g. GFA) along the fiber pathway. We use it to cluster fibers with a dictionary learning and sparse coding-based framework, and present a preliminary analysis using HCP data.},
	booktitle = {{MFCA} {MICCAI} {Workshop}},
	author = {Kumar, Kuldeep and Gori, Pietro and Charlier, Benjamin and Durrleman, Stanley and Colliot, Olivier and Desrosiers, Christian},
	year = {2017},
	pages = {92--100},
	abbr = {MICCAI-W}
}

@phdthesis{gori_statistical_2016,
	title = {Statistical models to learn the structural organisation of neural circuits from multimodal brain images : application to {Gilles} de la {Tourette} syndrome},
	url = {http://www.theses.fr/2016PA066057},
	abstract = {Nous proposons un cadre statistique pour analyser les anomalies morphologiques et organisationnelles alt√©rant l'anatomie des circuits neuronaux chez les patients atteints du syndrome de Gilles de la Tourette. Les composants de chaque circuit (mati√®re grise et blanche) sont repr√©sent√©s comme des maillages 3D et int√©gr√©s dans un seul complexe. Cela permet d'√©tudier leur organisation et surtout la connectivit√© structurelle. La m√©thode propos√©e est bas√©e sur une approche statistique appel√©e construction d'atlas qui r√©sulte en un template, capturant les invariants de la population, et en d√©formations template-vers-sujets, d√©crivant la variabilit√© morphologique. Premi√®rement, nous int√©grons la construction d'atlas dans un cadre bay√©sien qui permet d'estimer automatiquement des param√®tres autrement fix√©s. Deuxi√®mement, nous r√©duisons les ressources de calcul n√©cessaires au traitement de faisceaux de fibres en d√©finissant un sch√©ma d'approximation bas√©e sur un nouveau mod√®le appel√© courants pond√©r√©s. Troisi√®mement, nous d√©crivons un nouveau mod√®le de d√©formation pour la construction d'atlas qui permet de capturer les variations morphologiques et organisationnelles. On montre l'efficacit√© de la m√©thode par comparaison de deux groupes de 44 patients et 22 t√©moins. Les r√©sultats soulignent des anomalies sur la forme des structures de la mati√®re grise et sur la connectivit√© structurelle.},
	school = {Paris 6},
	author = {Gori, Pietro},
	year = {2016},
	abbr = {PhD thesis}
}

@article{gori_double_2018,
	title = {Double {Diffeomorphism}: {Combining} {Morphometry} and {Structural} {Connectivity} {Analysis}},
	volume = {37},
	doi = {10.1109/TMI.2018.2813062},
	abstract = {The brain is composed of several neural circuits which may be seen as anatomical complexes composed of grey matter structures interconnected by white matter tracts. Grey and white matter components may be modeled as 3-D surfaces and curves, respectively. Neurodevelopmental disorders involve morphological and organizational alterations which cannot be jointly captured by usual shape analysis techniques based on single diffeomorphisms. We propose a new deformation scheme, called double diffeomorphism, which is a combination of two diffeomorphisms. The first one captures changes in structural connectivity, whereas the second one recovers the global morphological variations of both grey and white matter structures. This deformation model is integrated into a Bayesian framework for atlas construction. We evaluate it on a data-set of 3-D structures representing the neural circuits of patients with Gilles de la Tourette syndrome (GTS). We show that this approach makes it possible to localise, quantify, and easily visualise the pathological anomalies altering the morphology and organization of the neural circuits. Furthermore, results also indicate that the proposed deformation model better discriminates between controls and GTS patients than a single diffeomorphism.},
	number = {9},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Gori, Pietro and Colliot, Olivier and Kacem, Linda Marrakchi and Worbe, Yulia and Routier, Alexandre and Poupon, Cyril and Hartmann, Andreas and Ayache, Nicholas and Durrleman, Stanley},
	year = {2018},
	pages = {2033--2043},
	abbr = {IEEE TMI}
}

@inproceedings{mercier_progressive_2018,
	title = {Progressive and {Efficient} {Multi}-{Resolution} {Representations} for {Brain} {Tractograms}},
	url = {https://diglib.eg.org:443/xmlui/handle/10.2312/vcbm20181232},
	doi = {10.2312/vcbm.20181232},
	abstract = {Current tractography methods generate tractograms composed of millions of 3D polylines, called fibers, making visualization and interpretation extremely challenging, thus complexifying the use of this technique in a clinical environment. We propose to progressively simplify tractograms by grouping similar fibers into generalized cylinders. This produces a fine-grained multiresolution model that provides a progressive and real-time navigation through different levels of detail. This model preserves the overall structure of the tractogram and can be adapted to different measures of similarity. We also provide an efficient implementation of the method based on a Delaunay tetrahedralization. We illustrate our method using the Human Connectome Project dataset.},
	booktitle = {Eurographics {Workshop} {VCBM}},
	author = {Mercier, Corentin and Gori, Pietro and Rohmer, Damien and Cani, Marie-Paule and Boubekeur, Tamy and Thiery, Jean-Marc and Bloch, Isabelle},
	year = {2018},
	abbr = {Eurographics-W},
	code={https://github.com/CorentinMercier/neural-meta-tracts}
}

@inproceedings{olivetti_comparison_2017,
	title = {Comparison of distances for supervised segmentation of white matter tractography},
	doi = {10.1109/PRNI.2017.7981502},
	abstract = {Tractograms are mathematical representations of the main paths of axons within the white matter of the brain, from diffusion MRI data. Such representations are in the form of polylines, called streamlines, and one streamline approximates the common path of tens of thousands of axons. The analysis of tractograms is a task of interest in multiple fields, like neurosurgery and neurology. A basic building block of many pipelines of analysis is the definition of a distance function between streamlines. Multiple distance functions have been proposed in the literature, and different authors use different distances, usually without a specific reason other than invoking the ‚Äúcommon practice‚Äù. To this end, in this work we want to test such common practices, in order to obtain factual reasons for choosing one distance over another. For these reason, in this work we compare many streamline distance functions available in the literature. We focus on the common task of automatic bundle segmentation and we adopt the recent approach of supervised segmentation from expert-based examples. Using the HCP dataset, we compare several distances obtaining guidelines on the choice of which distance function one should use for supervised bundle segmentation.},
	booktitle = {{International} {Workshop} on {Pattern} {Recognition} in {Neuroimaging} ({PRNI})},
	author = {Olivetti, Emanuele and Berto, Giulia and Gori, Pietro and Sharmin, Nusrat and Avesani, Paolo},
	year = {2017},
	pages = {1--4},
	abbr = {PRNI}
}

@inproceedings{virzi_segmentation_2018,
	title = {Segmentation of {Pelvic} {Vessels} in {Pediatric} {MRI} {Using} a {Patch}-{Based} {Deep} {Learning} {Approach}},
	doi = {10.1007/978-3-030-00807-9_10},
	abstract = {In this paper, we propose a patch-based deep learning approach to segment pelvic vessels in 3D MRI images of pediatric patients. For a given T2 weighted MRI volume, a set of 2D axial patches are extracted using a limited number of user-selected landmarks. In order to take into account the volumetric information, successive 2D axial patches are combined together, producing a set of pseudo RGB color images. These RGB images are then used as input for a convolutional neural network (CNN), pre-trained on the ImageNet dataset, which results into both segmentation and vessel labeling as veins or arteries. The proposed method is evaluated on 35 MRI volumes of pediatric patients, obtaining an average segmentation accuracy in terms of Average Symmetric Surface Distance of ùê¥ùëÜùëÜùê∑=0.89¬±0.07ASSD=0.89¬±0.07ASSD = 0.89 {\textbackslash}pm 0.07 mm and Dice Index of ùê∑ùê∂=0.79¬±0.02DC=0.79¬±0.02DC = 0.79 {\textbackslash}pm 0.02.},
	booktitle = {{PIPPI} {MICCAI} {Workshop}},
	author = {Virz√¨, A. and Gori, Pietro and Muller, C. O. and Mille, E. and Peyrot, Q. and Berteloot, L. and Boddaert, N. and Sarnacki, S. and Bloch, I.},
	year = {2018},
	pages = {97--106},
	abbr = {MICCAI-W}
}

@inproceedings{delmonte_white_2019,
	title = {White {Matter} {Multi}-{Resolution} {Segmentation} {Using} {Fuzzy} {Set} {Theory}},
	doi = {10.1109/ISBI.2019.8759506},
	abstract = {The neural architecture of the white matter of the brain, obtained using tractography algorithms, can be divided into different tracts. Their function is, in many cases, still an object of study and might be affected in some syndromes or conditions. Obtaining a reproducible and correct segmentation is therefore crucial both in clinics and in research. However, it is difficult to obtain due to the huge number of fibers and high inter-subject variability. In this paper, we propose to segment and recognize tracts by directly modeling their anatomical definitions, which are usually based on relationships between structures. Since these definitions are mainly qualitative, we propose to model their intrinsic vagueness using fuzzy spatial relations and combine them into a single quantitative score mapped to each fiber. To cope with the high redundancy of tractograms and ease interpretation, we also take advantage of a simplification scheme based on a multi-resolution representation. This allows for an interactive and real-time navigation through different levels of detail. We illustrate our method using the Human Connectome Project dataset and compare it to other well-known white matter segmentation techniques.},
	booktitle = {{IEEE} 16th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Delmonte, A. and Mercier, C. and Pallud, J. and Bloch, I. and Gori, Pietro},
	year = {2019},
	pages = {459--462},
	abbr = {IEEE ISBI},
	url={https://ieeexplore.ieee.org/document/8759506},
	code={https://github.com/PietroGori/FuzzyTracts}
}

@inproceedings{feydy_fast_2019,
	title = {Fast and {Scalable} {Optimal} {Transport} for {Brain} {Tractograms}},
	doi = {10.1007/978-3-030-32248-9_71},
	abstract = {We present a new multiscale algorithm for solving regularized Optimal Transport problems on the GPU, with a linear memory footprint. Relying on Sinkhorn divergences which are convex, smooth and positive definite loss functions, this method enables the computation of transport plans between millions of points in a matter of minutes. We show the effectiveness of this approach on brain tractograms modeled either as bundles of fibers or as track density maps. We use the resulting smooth assignments to perform label transfer for atlas-based segmentation of fiber tractograms. The parameters ‚Äì blur and reach ‚Äì of our method are meaningful, defining the minimum and maximum distance at which two fibers are compared with each other. They can be set according to anatomical knowledge. Furthermore, we also propose to estimate a probabilistic atlas of a population of track density maps as a Wasserstein barycenter. Our CUDA implementation is endowed with a user-friendly PyTorch interface, freely available on the PyPi repository (pip install geomloss) and at www.kernel-operations.io/geomloss.},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} ‚Äì {MICCAI}},
	author = {Feydy, Jean and Roussillon, Pierre and Trouv√©, Alain and Gori, Pietro},
	year = {2019},
	pages = {636--644},
	abbr = {MICCAI},
	url={https://link.springer.com/chapter/10.1007/978-3-030-32248-9_71},
	code={www.kernel-operations.io/geomloss}
}

@article{muller_integrating_2019,
	title = {Integrating tractography in pelvic surgery: a proof of concept},
	volume = {48},
	url = {http://www.sciencedirect.com/science/article/pii/S2213576619301800},
	doi = {10.1016/j.epsc.2019.101268},
	abstract = {Objective
To show the interest of tractography in pelvic surgery by a demonstrative case of neurofibroma resected by robotic assisted laparoscopy.
Summary background data
Although diffusion tensor magnetic resonance imaging, along with tractography algorithms, is increasingly included in image guided neurosurgery methods, it is less frequently used for the peripheral nervous system such as the pelvic sacral plexus. We report one observation demonstrating the interest of such image data for pelvic surgery.
Methods
A 12-years-old girl with neurofibromatosis presented with a growing left pelvic neurofibroma on repeated pelvic MRI with an increased SUV (2.83) on PET scan. A diffusion tensor pelvic MRI was performed before and after robotically assisted tumoral resection, and a tractography algorithm was applied on both images.
Results
The pre-operative tractogram showed the nervous nature of the tumor in close contact with the left sacral plexus. Section of a nerve trunk encased in the neurofibroma was mandatory for the resection and well documented by the 3D enhanced vision provided by the robot. Post-operatively, the patient showed a slight paresthesia and dysesthesia of the left leg calf and of the plantar vault (left S2 territory), without any motor deficit. The post-operative tractogram showed a thinning of the left S2 sacral root and the disappearance of right aberrant nervous tracts.
Conclusions
This clinical case validates the ability of pelvic tractography to deliver a proper imaging of the sacral nervous network and emphasizes the potential usefulness of this approach in pelvic surgery management, with perspectives of image-guided surgery.},
	journal = {Journal of Pediatric Surgery Case Reports},
	author = {Muller, C√©cile Olivia and Mille, Eva and Virzi, Alessio and Marret, Jean-Baptiste and Peyrot, Quoc and Delmonte, Alessandro and Berteloot, Laureline and Gori, Pietro and Blanc, Thomas and Grevent, David and Boddaert, Nathalie and Bloch, Isabelle and Sarnacki, Sabine},
	year = {2019},
	abbr = {J. Pediatric Surg.}
}

@inproceedings{roussillon_appariement_2019,
	title = {Appariement diff√©omorphique robuste de faisceaux neuronaux},
	url = {https://hal.telecom-paris.fr/hal-02264180},
	abstract = {Dans cet article, nous nous int√©ressons √† l'appariement diff√©omorphique de faisceaux du cerveau. Ce probl√®me est complexe car deux faisceaux n'ont presque jamais le m√™me nombre de fibres. Ces variations topologiques peuvent d√©t√©riorer les d√©formations obtenues et fausser les interpr√©tations cliniques. Nous proposons ici une m√©thode robuste aux diff√©rences topologiques, gr√¢ce √† la combinaison de normes L p et de m√©triques √† noyaux adapt√©es √† l'espace des fibres. Les r√©sultats sur des exemples jouets et sur des donn√©es r√©elles sont prometteurs. Abstract-In this article, we study the diffeomorphic matching of brain fibers bundles. This problem is complex because there is no topological correspondence between two bundles, namely two bundles do not have the same number of fibers. This strongly deteriorates the deformations obtained and can lead to a wrong clinical intepretation. We present a method that is robust to topological differences, by combining L p norms and kernel-based metrics adapted to the space of fibers. We test the effectivenes of our method on both toy examples and brain fiber bundles.},
	booktitle = {{GRETSI} 2019},
	author = {Roussillon, Pierre and Thiery, Jean-Marc and Bloch, Isabelle and Gori, Pietro},
	year = {2019},
	abbr = {GRETSI}
}


@article{baudouin:hal-04827492,
	TITLE = {{White matter hyperintensities and their role in major depressive episodes: a cross-sectional study in adults under 65}},
	AUTHOR = {Baudouin, {\'E}douard and Corruble, Emmanuelle and Gori, Pietro and Bloch, Isabelle and Becquemont, Laurent and Duron, Emmanuelle and Colle, Romain},
	URL = {https://telecom-paris.hal.science/hal-04827492},
	abstract={Objective: White matter hyperintensities (WMH) are associated with Major Depressive Episodes (MDE) in individuals aged 65 and over. WMH are prevalent in adults under 65, yet the association between their volume and MDE in this population remains uncertain. This study aimed to assess the association between WMH volume and MDE and its severity in patients < 65.
	Methods: This cross-sectional study included subjects under the age of 65, 69 patients with MDE and 32 healthy controls (HCs).  Severity was assessed with the Hamilton Rating Scale and WMH were quantified by 2 experts. Post-hoc mediation analyses were conducted if associations were found between independent variables and WMH.
	Results: Mean was 34.5 (12.4) years old. There was no difference in WMH between patients and HCs. Higher WMH volume were observed in extremely severe MDE (2170.2 (3767.9) mm3 vs 416.6 (594.9) mm3 (r = 0.218; p < 0.05)), which completely mediated the effect of age on severity.
	Conclusions: In adults under 65, this study failed to identify higher WMH volume in MDE compared to HCs. However, WMH may act as a mediator of the association between age and MDE severity. This finding suggests that WMH could contribute to more severe depression in late-life. },
	JOURNAL = {{Brazilian Journal of Psychiatry}},
	YEAR = {2025},
	abbr = {Braz. J. Psy.}
}

@article{roux_mri_2019,
	title = {{MRI} {Atlas} of {IDH} {Wild}-{Type} {Supratentorial} {Glioblastoma}: {Probabilistic}                    {Maps} of {Phenotype}, {Management}, and {Outcomes}},
	volume = {293},
	url = {https://pubs.rsna.org/doi/10.1148/radiol.2019190491},
	doi = {10.1148/radiol.2019190491},
	abstract = {BackgroundTumor location is a main prognostic parameter in patients with                            glioblastoma. Probabilistic MRI-based brain atlases specifying the                            probability of tumor location associated with important demographic,                            clinical, histomolecular, and management data are lacking for isocitrate                            dehydrogenase (IDH) wild-type glioblastomas.PurposeTo correlate glioblastoma location with clinical phenotype, surgical                            management, and outcomes by using a probabilistic analysis in a                            three-dimensional (3D) MRI-based atlas.Materials and MethodsThis retrospective study included all adults surgically treated for newly                            diagnosed IDH wild-type supratentorial glioblastoma in a tertiary adult                            surgical neuro-oncology center (2006‚Äì2016). Semiautomated tumor                            segmentation and spatial normalization procedures to build a 3D                            MRI-based atlas were validated. The authors performed probabilistic                            analyses by using voxel-based lesion symptom mapping technology. The                            Liebermeister test was used for binary data, and the generalized linear                            model was used for continuous data.ResultsA total of 392 patients (mean age, 61 years ¬± 13; 233 men) were                            evaluated. The authors identified the preferential location of                            glioblastomas according to subventricular zone, age, sex, clinical                            presentation, revised Radiation Therapy Oncology Group-Recursive                            Partitioning Analysis class, Karnofsky performance status,                            O6-methylguanine DNA methyltransferase promoter methylation                            status, surgical management, and survival. The superficial location                            distant from the eloquent area was more likely associated with a                            preserved functional status at diagnosis (348 of 392 patients [89\%],                                P {\textless} .05), a large surgical resection (173 of                            392 patients [44\%], P {\textless} .05), and prolonged                            overall survival (163 of 334 patients [49\%], P {\textless}                            .05). In contrast, deep location and location within eloquent brain                            areas were more likely associated with an impaired functional status at                            diagnosis (44 of 392 patients [11\%], P {\textless} .05), a                            neurologic deficit (282 of 392 patients [72\%], P {\textless}                            .05), treatment with biopsy only (183 of 392 patients [47\%],                                P {\textless} .05), and shortened overall survival (171                            of 334 patients [51\%], P {\textless} .05).ConclusionThe authors identified the preferential location of isocitrate                            dehydrogenase wild-type glioblastomas according to parameters of                            interest and provided an image-based integration of multimodal                            information impacting survival results. This suggests the role of                            glioblastoma location as a surrogate and multimodal parameter                            integrating several known prognostic factors.¬© RSNA, 2019Online supplemental material is available for this                                    article.See also the editorial by Huang in this issue.},
	number = {3},
	journal = {Radiology},
	author = {Roux, Alexandre and Roca, Pauline and Edjlali, Myriam and Sato, Kanako and Zanello, Marc and Dezamis, Edouard and Gori, Pietro and Lion, St√©phanie and Fleury, Ariane and Dhermain, Fr√©d√©ric and Meder, Jean-Fran√ßois and Chr√©tien, Fabrice and Lechapt, Emmanu√®le and Varlet, Pascale and Oppenheim, Catherine and Pallud, Johan},
	year = {2019},
	pages = {633--643},
	abbr={Radiology}
}

@incollection{charon_fidelity_2020,
	title = {Fidelity metrics between curves and surfaces: currents, varifolds, and normal cycles},
	url = {http://www.sciencedirect.com/science/article/pii/B9780128147252000212},
	abstract = {This chapter provides an overview of some mathematical and computational models that have been proposed over the past few years for defining data attachment terms on shape spaces of curves or surfaces. In all these models shapes are seen as elements of a space of generalized distributions, such as currents or varifolds. Then norms are defined through reproducing kernel Hilbert spaces (RKHS), which lead to shape distances that can be conveniently computed in practice. These were originally introduced in conjunction with diffeomorphic methods in computational anatomy and have indeed proved to be very efficient in this field. We provide a basic description of these different models and their practical implementation, then discuss the respective properties and potential advantages or downsides of each of them in diffeomorphic registration problems.},
	booktitle = {Riemannian {Geometric} {Statistics} in {Medical} {Image} {Analysis}},
	author = {Charon, Nicolas and Charlier, Benjamin and Glaun√®s, Joan and Gori, Pietro and Roussillon, Pierre},
	year = {2020},
	doi = {10.1016/B978-0-12-814725-2.00021-2},
	pages = {441--477},
	abbr={GSI}
}

@inproceedings{hu_knowledge_2020,
	title = {Knowledge {Distillation} from {Multi}-modal to {Mono}-modal {Segmentation} {Networks}},
	doi = {10.1007/978-3-030-59710-8_75},
	abstract = {The joint use of multiple imaging modalities for medical image segmentation has been widely studied in recent years. The fusion of information from different modalities has demonstrated to improve the segmentation accuracy, with respect to mono-modal segmentations, in several applications. However, acquiring multiple modalities is usually not possible in a clinical setting due to a limited number of physicians and scanners, and to limit costs and scan time. Most of the time, only one modality is acquired. In this paper, we propose KD-Net, a framework to transfer knowledge from a trained multi-modal network (teacher) to a mono-modal one (student). The proposed method is an adaptation of the generalized distillation framework where the student network is trained on a subset (1 modality) of the teacher‚Äôs inputs (n modalities). We illustrate the effectiveness of the proposed framework in brain tumor segmentation with the BraTS 2018 dataset. Using different architectures, we show that the student network effectively learns from the teacher and always outperforms the baseline mono-modal network in terms of segmentation accuracy.},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} ‚Äì {MICCAI}},
	author = {Hu, Minhao and Maillard, Matthis and Zhang, Ya and Ciceri, Tommaso and La Barbera, Giammarco and Bloch, Isabelle and Gori, Pietro},
	year = {2020},
	pages = {772--781},
	abbr={MICCAI},
	url={https://link.springer.com/chapter/10.1007/978-3-030-59710-8_75}
}

@article{mercier_qfib_2020,
	title = {{QFib}: {Fast} and {Efficient} {Brain} {Tractogram} {Compression}},
	abstract = {Diffusion MRI Ô¨Åber tracking datasets can contain millions of 3D streamlines, and their representation can weight tens of gigabytes of memory. These sets of streamlines are called tractograms and are often used for clinical operations or research. Their size makes them difÔ¨Åcult to store, visualize, process or exchange over the network. We propose a new compression algorithm well-suited for tractograms, by taking advantage of the way streamlines are obtained with usual tracking algorithms. Our approach is based on unit vector quantization methods combined with a spatial transformation which results in low compression and decompression times, as well as a high compression ratio. For instance, a 11.5GB tractogram can be compressed to a 1.02GB Ô¨Åle and decompressed in 11.3 seconds. Moreover, our method allows for the compression and decompression of individual streamlines, reducing the need for a costly outof-core algorithm with heavy datasets. Last, we open a way toward on-the-Ô¨Çy compression and decompression for handling larger datasets without needing a load of RAM (i.e. in-core handling), faster network exchanges and faster loading times for visualization or processing.},
	journal = {Neuroinformatics},
	author = {Mercier, Corentin and Rousseau, S and Gori, P and Bloch, I and Boubekeur, T},
	year = {2020},
	pages = {13},
	url={https://link.springer.com/article/10.1007/s12021-020-09452-0},
	abbr={Neuroinformatics},
	code={https://github.com/syrousseau/qfib}
}

@inproceedings{riva_template-based_2020,
	title = {Template-{Based} {Graph} {Clustering}},
	abstract = {We propose a novel graph clustering method guided by additional information on the underlying structure of the clusters (or communities). The problem is formulated as the matching of a graph to a template with smaller dimension, hence matching n vertices of the observed graph (to be clustered) to the k vertices of a template graph, using its edges as support information, and relaxed on the set of orthonormal matrices in order to Ô¨Ånd a k dimensional embedding. With relevant priors that encode the density of the clusters and their relationships, our method outperforms classical methods, especially for challenging cases.},
	booktitle = {{GEM} - {ECML}-{PKDD} {Workshop}},
	author = {Riva, Mateus and Yger, Florian and Gori, Pietro and Jr, Roberto M Cesar and Bloch, Isabelle},
	year = {2020},
	pages = {16},
	abbr={ECML/PKDD-W},
	code={https://github.com/mateusriva/TBGC},
	url={https://arxiv.org/abs/2107.01994}
}

@article{virzi_comprehensive_2020,
	title = {Comprehensive {Review} of {3D} {Segmentation} {Software} {Tools} for {MRI} {Usable} for {Pelvic} {Surgery} {Planning}},
	volume = {33},
	url = {https://doi.org/10.1007/s10278-019-00239-7},
	doi = {10.1007/s10278-019-00239-7},
	abstract = {Patient-specific 3D modeling is the first step towards image-guided surgery, the actual revolution in surgical care. Pediatric and adolescent patients with rare tumors and malformations should highly benefit from these latest technological innovations, allowing personalized tailored surgery. This study focused on the pelvic region, located at the crossroads of the urinary, digestive, and genital channels with important vascular and nervous structures. The aim of this study was to evaluate the performances of different software tools to obtain patient-specific 3D models, through segmentation of magnetic resonance images (MRI), the reference for pediatric pelvis examination. Twelve software tools freely available on the Internet and two commercial software tools were evaluated using T2-w MRI and diffusion-weighted MRI images. The software tools were rated according to eight criteria, evaluated by three different users: automatization degree, segmentation time, usability, 3D visualization, presence of image registration tools, tractography tools, supported OS, and potential extension (i.e., plugins). A ranking of software tools for 3D modeling of MRI medical images, according to the set of predefined criteria, was given. This ranking allowed us to elaborate guidelines for the choice of software tools for pelvic surgical planning in pediatric patients. The best-ranked software tools were Myrian Studio, ITK-SNAP, and 3D Slicer, the latter being especially appropriate if nerve fibers should be included in the 3D patient model. To conclude,¬†this study proposed a comprehensive review of software tools for 3D modeling of the pelvis according to a set of eight criteria and delivered specific conclusions for pediatric and adolescent patients that can be directly applied to clinical practice.},
	number = {1},
	journal = {Journal of Digital Imaging},
	author = {Virz√¨, Alessio and Muller, C√©cile Olivia and Marret, Jean-Baptiste and Mille, Eva and Berteloot, Laureline and Gr√©vent, David and Boddaert, Nathalie and Gori, Pietro and Sarnacki, Sabine and Bloch, Isabelle},
	year = {2020},
	pages = {99--110},
	abbr={JDI}
}

@article{zanello_automated_2020,
	title = {Automated neurosurgical stereotactic planning for intraoperative use: a comprehensive review of the literature and perspectives},
	url = {http://link.springer.com/10.1007/s10143-020-01315-1},
	doi = {10.1007/s10143-020-01315-1},
	abstract = {The creation of intracranial stereotactic trajectories, from entry point to target point, is still mostly done manually by the neurosurgeon. The development of automated stereotactic planning tools has been described in the literature. This systematic review aims to assess the effectiveness of stereotactic planning procedure automation and develop tools for patients undergoing neurosurgical stereotactic procedures. PubMed/MEDLINE, EMBASE, Google Scholar, CINAHL, PsycINFO, and Cochrane Register of Controlled Trials databases were searched from inception to September 1, 2019, at the exception of Google Scholar (from 1 January 2010 to September 1, 2019) in French and English. Eligible studies included all studies proposing automated stereotactic planning. A total of 1543 studies were screened. Forty-two studies were included in the systematic review, including 18 (42.9\%) conference papers. The surgical procedures planned automatically were mainly deep brain stimulation (n = 14, 33.3\%), stereoelectroencephalography (n = 12, 28.6\%), and not specified (n = 10, 23.8\%). The most frequently used surgical constraints to plan the trajectory were blood vessels (n = 32, 76.2\%), cerebral sulci (n = 27, 64.3\%), and cerebral ventricles (n = 23, 54.8\%). The distance from blood vessels ranged from 1.96 to 4.78 mm for manual trajectories and from 2.47 to 7.0 mm for automated trajectories. At least one neurosurgeon was involved in 36 studies (85.7\%). The automated stereotactic trajectory was preferred in 75.4\% of the studied cases (range 30‚Äì92.9). Only 3 (7.1\%) studies were multicentric. No study reported prospective use of the planning software. Stereotactic planning automation is a promising tool to provide valuable stereotactic trajectories for clinical applications.},
	journal = {Neurosurgical Review},
	author = {Zanello, Marc and Carron, Romain and Peeters, Sophie and Gori, Pietro and Roux, Alexandre and Bloch, Isabelle and Oppenheim, Catherine and Pallud, Johan},
	year = {2020},
	abbr={Neurosurgical Review}
}

@inproceedings{francois_metamorphic_2021,
	title = {Metamorphic {Image} {Registration} {Using} a¬†{Semi}-lagrangian {Scheme}},
	doi = {10.1007/978-3-030-80209-7_84},
	abstract = {In this paper, we propose an implementation of both Large Deformation Diffeomorphic Metric Mapping (LDDMM) and Metamorphosis image registration using a semi-Lagrangian scheme for geodesic shooting. We propose to solve both problems as an inexact matching providing a single and unifying cost function. We demonstrate that for image registration the use of a semi-Lagrangian scheme is more stable than a standard Eulerian scheme. Our GPU implementation is based on PyTorch, which greatly simplifies and accelerates the computations thanks to its powerful automatic differentiation engine. It will be freely available at https://github.com/antonfrancois/Demeter\_metamorphosis.},
	booktitle = {Geometric {Science} of {Information}},
	author = {Fran√ßois, Anton and Gori, Pietro and Glaun√®s, Joan},
	year = {2021},
	pages = {781--788},
	abbr={GSI},
	url={https://link.springer.com/chapter/10.1007/978-3-030-80209-7_84},
	code={https://github.com/antonfrancois/Demeter_metamorphosis}
}

@inproceedings{kips_deep_2021,
	title = {Deep {Graphics} {Encoder} for {Real}-{Time} {Video} {Makeup} {Synthesis} from {Example}},
	doi = {10.1109/CVPRW53098.2021.00431},
	abstract = {While makeup virtual-try-on is now widespread, parametrizing a computer graphics rendering engine for synthesizing images of a given cosmetics product remains a challenging task. In this paper, we introduce an inverse computer graphics method for automatic makeup synthesis from a reference image, by learning a model that maps an example portrait image with makeup to the space of rendering parameters. This method can be used by artists to automatically create realistic virtual cosmetics image samples, or by consumers, to virtually try-on a makeup extracted from their favorite reference image.},
	booktitle = {{IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	author = {Kips, Robin and Jiang, Ruowei and Ba, Sileye and Phung, Edmund and Aarabi, Parham and Gori, Pietro and Perrot, Matthieu and Bloch, Isabelle},
	year = {2021},
	pages = {3884--3888},
	abbr={CVPR-W},
	url={https://robinkips.github.io/DeepMakeupGraphicsEncoder/}
}

@inproceedings{la_barbera_automatic_2021,
	title = {Automatic {Size} {And} {Pose} {Homogenization} {With} {Spatial} {Transformer} {Network} {To} {Improve} {And} {Accelerate} {Pediatric} {Segmentation}},
	doi = {10.1109/ISBI48211.2021.9434090},
	abstract = {Due to a high heterogeneity in pose and size and to a limited number of available data, segmentation of pediatric images is challenging for deep learning methods. In this work, we propose a new CNN architecture that is pose and scale invariant thanks to the use of Spatial Transformer Network (STN). Our architecture is composed of three sequential modules that are estimated together during training: (i) a regression module to estimate a similarity matrix to normalize the input image to a reference one; (ii) a differentiable module to find the region of interest to segment; (iii) a segmentation module, based on the popular UNet architecture, to delineate the object. Unlike the original UNet, which strives to learn a complex mapping, including pose and scale variations, from a finite training dataset, our segmentation module learns a simpler mapping focusing on images with normalized pose and size. Furthermore, the use of an automatic bounding box detection through STN allows saving time and especially memory, while keeping similar performance. We test the proposed method in kidney and renal tumor segmentation on abdominal pediatric CT scanners. Results indicate that the estimated STN homogenization of size and pose accelerates the segmentation (25h), compared to standard data-augmentation (33h), while obtaining a similar quality for the kidney (88.01\% of Dice score) and improving the renal tumor delineation (from 85.52\% to 87.12\%).},
	booktitle = {{IEEE} 18th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {La Barbera, Giammarco La and Gori, Pietro and Boussaid, Haithem and Belucci, Bruno and Delmonte, Alessandro and Goulin, Jeanne and Sarnacki, Sabine and Rouet, Laurence and Bloch, Isabelle},
	year = {2021},
	pages = {1773--1776},
	abbr={IEEE ISBI},
	url={https://ieeexplore.ieee.org/document/9434090},
	code={https://github.com/Giammarco07/DeePRAC_project}
}

@article{routier_clinica_2021,
	title = {Clinica: {An} {Open}-{Source} {Software} {Platform} for {Reproducible} {Clinical} {Neuroscience} {Studies}},
	volume = {15},
	url = {https://www.frontiersin.org/articles/10.3389/fninf.2021.689675},
	abstract = {We present Clinica (www.clinica.run), an open-source software platform designed to make clinical neuroscience studies easier and more reproducible. Clinica aims for researchers to (i) spend less time on data management and processing, (ii) perform reproducible evaluations of their methods, and (iii) easily share data and results within their institution and with external collaborators. The core of Clinica is a set of automatic pipelines for processing and analysis of multimodal neuroimaging data (currently, T1-weighted MRI, diffusion MRI, and PET data), as well as tools for statistics, machine learning, and deep learning. It relies on the brain imaging data structure (BIDS) for the organization of raw neuroimaging datasets and on established tools written by the community to build its pipelines. It also provides converters of public neuroimaging datasets to BIDS (currently ADNI, AIBL, OASIS, and NIFD). Processed data include image-valued scalar fields (e.g., tissue probability maps), meshes, surface-based scalar fields (e.g., cortical thickness maps), or scalar outputs (e.g., regional averages). These data follow the ClinicA Processed Structure (CAPS) format which shares the same philosophy as BIDS. Consistent organization of raw and processed neuroimaging files facilitates the execution of single pipelines and of sequences of pipelines, as well as the integration of processed data into statistics or machine learning frameworks. The target audience of Clinica is neuroscientists or clinicians conducting clinical neuroscience studies involving multimodal imaging, and researchers developing advanced machine learning algorithms applied to neuroimaging data.},
	journal = {Frontiers in Neuroinformatics},
	author = {Routier, Alexandre and Burgos, Ninon and D√≠az, Mauricio and Bacci, Michael and Bottani, Simona and El-Rifai, Omar and Fontanella, Sabrina and Gori, Pietro and Guillon, J√©r√©my and Guyot, Alexis and Hassanaly, Ravi and Jacquemont, Thomas and Lu, Pascal and Marcoux, Arnaud and Moreau, Tristan and Samper-Gonz√°lez, Jorge and Teichmann, Marc and Thibeau-Sutre, Elina and Vaillant, Ghislain and Wen, Junhao and Wild, Adam and Habert, Marie-Odile and Durrleman, Stanley and Colliot, Olivier},
	year = {2021},
	abbr={Frontiers in Neuroinformatics}
}

@article{kips_real-time_2022,
	title = {Real-time {Virtual}-{Try}-{On} from a {Single} {Example} {Image} through {Deep} {Inverse} {Graphics} and {Learned} {Differentiable} {Renderers}},
	volume = {41},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14456},
	doi = {10.1111/cgf.14456},
	abstract = {Augmented reality applications have rapidly spread across online retail platforms and social media, allowing consumers to virtually try-on a large variety of products, such as makeup, hair dying, or shoes. However, parametrizing a renderer to synthesize realistic images of a given product remains a challenging task that requires expert knowledge. While recent work has introduced neural rendering methods for virtual try-on from example images, current approaches are based on large generative models that cannot be used in real-time on mobile devices. This calls for a hybrid method that combines the advantages of computer graphics and neural rendering approaches. In this paper, we propose a novel framework based on deep learning to build a real-time inverse graphics encoder that learns to map a single example image into the parameter space of a given augmented reality rendering engine. Our method leverages self-supervised learning and does not require labeled training data, which makes it extendable to many virtual try-on applications. Furthermore, most augmented reality renderers are not differentiable in practice due to algorithmic choices or implementation constraints to reach real-time on portable devices. To relax the need for a graphics-based differentiable renderer in inverse graphics problems, we introduce a trainable imitator module. Our imitator is a generative network that learns to accurately reproduce the behavior of a given non-differentiable renderer. We propose a novel rendering sensitivity loss to train the imitator, which ensures that the network learns an accurate and continuous representation for each rendering parameter. Automatically learning a differentiable renderer, as proposed here, could be beneficial for various inverse graphics tasks. Our framework enables novel applications where consumers can virtually try-on a novel unknown product from an inspirational reference image on social media. It can also be used by computer graphics artists to automatically create realistic rendering from a reference product image.},
	number = {2},
	journal = {Computer Graphics Forum},
	author = {Kips, R. and Jiang, R. and Ba, S. and Duke, B. and Perrot, M. and Gori, Pietro and Bloch, I.},
	year = {2022},
	pages = {29--40},
	abbr={Eurographics}
}

@inproceedings{riva_is_2022,
	title = {Is the {U}-{Net} {Directional}-{Relationship} {Aware}?},
	booktitle = {International {Conference} on {Image} {Processing} ({ICIP})},
	author = {Riva, Mateus and Gori, Pietro and Yger, Florian and Bloch, Isabelle},
	year = {2022},
	abbr={IEEE ICIP},
	url={https://arxiv.org/pdf/2207.02574},
	doi={10.1109/ICIP46576.2022.9897715}
}

@inproceedings{kips_hair_2022,
	title = {Hair color digitization through imaging and deep inverse graphics},
	volume = {34},
	url = {https://library.imaging.org/ei/articles/34/10/IPAS-383},
	doi = {10.2352/EI.2022.34.10.IPAS-383},
	abstract = {Abstract Hair appearance is a complex phenomenon due to hair geometry and how the light bounces on different hair fibers. For this reason, reproducing a specific hair color in a rendering environment is a challenging task that requires manual work and expert knowledge in computer graphics to tune the result visually. While current hair capture methods focus on hair shape estimation many applications could benefit from an automated method for capturing the appearance of a physical hair sample, from augmented/virtual reality to hair dying development. Building on recent advances in inverse graphics and material capture using deep neural networks, we introduce a novel method for hair color digitization. Our proposed pipeline allows capturing the color appearance of a physical hair sample and renders synthetic images of hair with a similar appearance, simulating different hair styles and/or lighting environments. Since rendering realistic hair images requires path-tracing rendering, the conventional inverse graphics approach based on differentiable rendering is untractable. Our method is based on the combination of a controlled imaging device, a path-tracing renderer, and an inverse graphics model based on self-supervised machine learning, which does not require to use differentiable rendering to be trained. We illustrate the performance of our hair digitization method on both real and synthetic images and show that our approach can accurately capture and render hair color.},
	language = {en},
	booktitle = {Electronic {Imaging}},
	author = {Kips, Robin and Bokaris, Panagiotis-Alexandros and Perrot, Matthieu and Gori, Pietro and Bloch, Isabelle},
	year = {2022},
	abbr={Electronic Imaging}
}

@inproceedings{la_barbera_anatomically_2022,
	title = {Anatomically constrained {CT} image translation for heterogeneous blood vessel segmentation},
	abstract = {Anatomical structures such as blood vessels in contrast-enhanced CT (ceCT) images can be challenging to segment due to the variability in contrast medium diffusion. The combined use of ceCT and contrast-free (CT) CT images can improve the segmentation performances, but at the cost of a double radiation exposure. To limit the radiation dose, generative models could be used to synthesize one modality, instead of acquiring it. The CycleGAN approach has recently attracted particular attention because it alleviates the need for paired data that are difficult to obtain. Despite the great performances demonstrated in the literature, limitations still remain when dealing with 3D volumes generated slice by slice from unpaired datasets with different fields of view. We present an extension of CycleGAN to generate high fidelity images, with good structural consistency, in this context. We leverage anatomical constraints and automatic region of interest selection by adapting the Self-Supervised Body Regressor. These constraints enforce anatomical consistency and allow feeding anatomically-paired input images to the algorithm. Results show qualitative and quantitative improvements, compared to stateof-the-art methods, on the translation task between ceCT and CT images (and vice versa).},
	booktitle = {British {Machine} {Vision} {Conference} ({BMVC})},
	author = {La Barbera, Giammarco and Boussaid, Haithem and Maso, Francesco and Sarnacki, Sabine and Rouet, Laurence and Gori, Pietro and Bloch, Isabelle},
	year = {2022},
	abbr={BMVC},
	url={https://bmvc2022.mpi-inf.mpg.de/0776.pdf}

}

@inproceedings{maillard_deep_2022,
	title = {A {Deep} {Residual} {Learning} {Implementation} of {Metamorphosis}},
	doi = {10.1109/ISBI52829.2022.9761422},
	abstract = {In medical imaging, most of the image registration methods implicitly assume a one-to-one correspondence between the source and target images (i.e., diffeomorphism). However, this is not necessarily the case when dealing with pathological medical images (e.g., presence of a tumor, lesion, etc.). To cope with this issue, the Metamorphosis model has been proposed. It modifies both the shape and the appearance of an image to deal with the geometrical and topological differences. However, the high computational time and load have hampered its applications so far. Here, we propose a deep residual learning implementation of Metamorphosis that drastically reduces the computational time at inference. Furthermore, we also show that the proposed framework can easily integrate prior knowledge of the localization of topological changes (e.g., segmentation masks) that can act as spatial regularization to correctly disentangle appearance and shape changes. We test our method on the BraTS 2021 dataset, showing that it outperforms current state-of-the-art methods in the alignment of images with brain tumors.},
	booktitle = {2022 {IEEE} 19th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Maillard, Matthis and Fran√ßois, Anton and Glaun√®s, Joan and Bloch, Isabelle and Gori, Pietro},
	year = {2022},
	pages = {1--4},
	abbr={IEEE ISBI},
	url={https://arxiv.org/pdf/2202.00676},
	code={https://github.com/mattmail/ResNet_Metamorphoses}
}

@inproceedings{barbano_contrastive_2023,
	title = {Contrastive learning for regression in multi-site brain age prediction},
	abstract = {Building accurate Deep Learning (DL) models for brain age prediction is a very relevant topic in neuroimaging, as it could help better understand neurodegenerative disorders and find new biomarkers. To estimate accurate and generalizable models, large datasets have been collected, which are often multi-site and multi-scanner. This large heterogeneity negatively affects the generalization performance of DL models since they are prone to overfit site-related noise. Recently, contrastive learning approaches have been shown to be more robust against noise in data or labels. For this reason, we propose a novel contrastive learning regression loss for robust brain age prediction using MRI scans. Our method achieves state-of-the-art performance on the OpenBHB challenge, yielding the best generalization capability and robustness to site-related noise.},
	booktitle = {{IEEE} 20th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Barbano, Carlo Alberto and Dufumier, Benoit and Duchesnay, Edouard and Grangetto, Marco and Gori, Pietro},
	year = {2023},
	abbr={IEEE ISBI},
	url={https://arxiv.org/pdf/2211.08326},
	code={https://github.com/EIDOSLAB/contrastive-brain-age-prediction}
}

@inproceedings{ruppli_optimizing_2022,
	title = {Optimizing {Transformations} for¬†{Contrastive} {Learning} in¬†a¬†{Differentiable} {Framework}},
	doi = {10.1007/978-3-031-16760-7_10},
	abstract = {Current contrastive learning methods use random transformations sampled from a large list of transformations, with fixed hyper-parameters, to learn invariance from an unannotated database. Following previous works that introduce a small amount of supervision, we propose a framework to find optimal transformations for contrastive learning using a differentiable transformation network. Our method increases performances at low annotated data regime both in supervision accuracy and in convergence speed. In contrast to previous work, no generative model is needed for transformation optimization. Transformed images keep relevant information to solve the supervised task, here classification. Experiments were performed on 34000 2D slices of brain Magnetic Resonance Images and 11200 chest X-ray images. On both datasets, with 10\% of labeled data, our model achieves better performances than a fully supervised model with 100\% labels.},
	booktitle = {Medical {Image} {Learning} with {Limited} and {Noisy} {Data} - {MILLanD} ({Workshop} {MICCAI})},
	author = {Ruppli, Camille and Gori, Pietro and Ardon, Roberto and Bloch, Isabelle},
	year = {2022},
	abbr={MICCAI-W},
	url={https://arxiv.org/pdf/2207.13367}
}

@inproceedings{vetil_learning_2022,
	title = {Learning {Shape} {Distributions} from¬†{Large} {Databases} of¬†{Healthy} {Organs}: {Applications} to¬†{Zero}-{Shot} and¬†{Few}-{Shot} {Abnormal} {Pancreas} {Detection}},
	doi = {10.1007/978-3-031-16434-7_45},
	abstract = {We propose a scalable and data-driven approach to learn shape distributions from large databases of healthy organs. To do so, volumetric segmentation masks are embedded into a common probabilistic shape space that is learned with a variational auto-encoding network. The resulting latent shape representations are leveraged to derive zero-shot and few-shot methods for abnormal shape detection. The proposed distribution learning approach is illustrated on a large database of 1200 healthy pancreas shapes. Downstream qualitative and quantitative experiments are conducted on a separate test set of 224 pancreas from patients with mixed conditions. The abnormal pancreas detection AUC reached up to \$\$65.41{\textbackslash}\%\$\$65.41\%in the zero-shot configuration, and \$\$78.97{\textbackslash}\%\$\$78.97\%in the few-shot configuration with as few as 15 abnormal examples, outperforming a baseline approach based on the sole volume.},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} ‚Äì {MICCAI}},
	author = {V√©til, Rebeca and Abi-Nader, Cl√©ment and B√¥ne, Alexandre and Vullierme, Marie-Pierre and Roh√©, Marc-Michel and Gori, Pietro and Bloch, Isabelle},
	year = {2022},
	pages = {464--473},
	abbr={MICCAI},
	url={https://arxiv.org/pdf/2210.12095}
}

@inproceedings{vetil_improving_2022,
	title = {Improving the {Automatic} {Segmentation} of {Elongated} {Organs} {Using} {Geometrical} {Priors}},
	doi = {10.1109/ISBI52829.2022.9761555},
	abstract = {Deep neural networks are widely used for automated organ segmentation as they achieve promising results for clinical applications. Some organs are more challenging to delineate than others, for instance due to low contrast at their boundaries. In this paper, we propose to improve the segmentation of elongated organs thanks to Geometrical Priors that can be introduced during training, using a local Tversky loss function, or at post-processing, using local thresholds. Both strategies do not introduce additional training parameters and can be easily applied to any existing network. The proposed method is evaluated on the challenging problem of pancreas segmentation. Results show that Geometrical Priors allow us to correct the systematic under-segmentation pattern of a state-of-the-art method, while preserving the overall segmentation quality.},
	booktitle = {{IEEE} 19th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {V√©til, Rebeca and B√¥ne, Alexandre and Vullierme, Marie-Pierre and Roh√©, Marc-Michel and Gori, Pietro and Bloch, Isabelle},
	year = {2022},
	pages = {1--4},
	abbr={IEEE ISBI},
	url={https://telecom-paris.hal.science/hal-03628860v1/file/vetil_isbi_2022_final_version.pdf}
}

@inproceedings{sarfati_learning_2023,
	title = {Learning to diagnose cirrhosis from radiological and histological labels with joint self and weakly-supervised pretraining strategies},
	abstract = {Identifying cirrhosis is key to correctly assess the health of the liver. However, the gold standard diagnosis of the cirrhosis needs a medical intervention to obtain the histological confirmation, e.g. the METAVIR score, as the radiological presentation can be equivocal. In this work, we propose to leverage transfer learning from large datasets annotated by radiologists, which we consider as a weak annotation, to predict the histological score available on a small annex dataset. To this end, we propose to compare different pretraining methods, namely weakly-supervised and self-supervised ones, to improve the prediction of the cirrhosis. Finally, we introduce a loss function combining both supervised and self-supervised frameworks for pretraining. This method outperforms the baseline classification of the METAVIR score, reaching an AUC of 0.84 and a balanced accuracy of 0.75, compared to 0.77 and 0.72 for a baseline classifier.},
	booktitle = {{IEEE} 20th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Sarfati, Emma and Bone, Alexandre and Rohe, Marc-Michel and Gori, Pietro and Bloch, Isabelle},
	year = {2023},
	url={https://arxiv.org/pdf/2302.08427},
	abbr={IEEE ISBI},
	doi={10.1109/ISBI53787.2023.10230783}
}

@inproceedings{dufumier_integrating_2023,
	title = {Integrating {Prior} {Knowledge} in {Contrastive} {Learning} with {Kernel}},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	author = {Dufumier, Benoit and Barbano, Carlo Alberto and Louiset, Robin and Duchesnay, Edouard and Gori, Pietro},
	year = {2023},
	abbr={ICML},
	url={https://proceedings.mlr.press/v202/dufumier23a.html},
	code={https://github.com/Duplums/contrastive-decoupled-uniformity}
}

@inproceedings{auriau_supervised_2024,
	title = {Supervised diagnosis prediction from cortical sulci: toward the discovery of neurodevelopmental biomarkers in mental disorders},
	booktitle = {21st {IEEE} {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Auriau, Pierre and Grigis, Antoine and Dufumier, Benoit and Louiset, Robin and Chavas, Joel and Gori, Pietro and Mangin, Jean-Fran√ßois and Duchesnay, Edouard},
	year = {2024},
	abbr={IEEE ISBI},
	url={https://hal.science/hal-04494994v1/document},
	doi={10.1109/ISBI56570.2024.10635738}
}

@inproceedings{mounime_sparsity_2024,
	title = {Sparsity {Constrained} {Linear} {Tangent} {Space} {Alignment} {Model} ({sLTSA}) for {3D} {Cardiac} {Extracellular} {Volume} {Mapping}},
	booktitle = {21st {IEEE} {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Mounime, Isma√´l and Lee, Wonil and Marin, Thibault and Han, Paul K and Djebra, Yanis and Eslahi, Samira V and Gori, Pietro and Angelini, Elsa and Fakhri, Georges El and Ma, Chao},
	year = {2024},
	abbr={IEEE ISBI},
	abstract={Cardiac longitudinal relaxation time (T 1 ) and extracellular volume (ECV) are valuable bio-markers used for the quantitative characterization of cardiac tissue properties, showing great potential in many clinical applications such as diffuse fibrosis. However, cardiac T 1 and ECV mapping is difficult because of respiratory and cardiac motions. A unique challenge for post-contrast T 1 mapping is that the concentration of contrast agent also changes over time. Recently, a linear tangent space alignment (LTSA) model-based fast MRI method has been proposed to enable high-resolution, high-frame-rate dynamic MR with sparsely sampled (k, t)-space data by leveraging the intrinsic low-dimensional manifold structure of dynamic MR images, showing superior performance over the low-rank model-based methods. This work extends the LTSA method by imposing an additional sparsity constraint on the subspace alignment matrix of the LTSA model for improved image reconstruction. The performance of the proposed method is validated in 3D free-breathing, pre- and post-contrast cardiac T 1 mapping as well as ECV mapping using in vivo data acquired on healthy volunteers at 3T.},
	url={https://telecom-paris.hal.science/hal-04479822v1/document},
	doi={10.1109/ISBI56570.2024.10635692}
}

@patent{vetil_method_2024,
	title = {Method for characterizing an organ of a patient in a medical image},
	number = {EP22194886.2},
	author = {V√©til, Rebeca and Abi-Nader, Cl√©ment and B√¥ne, Alexandre and Roh√©, Marc-Michel and Gori, Pietro and Bloch, Isabelle},
	year = {2024},
	abbr={PATENT}
}

@patent{delmonte_automatic_2023,
	title = {Automatic generation of {3D} anatomical models},
	number = {EP22307002.0},
	author = {Delmonte, Alessandro and Sarnacki, Sabine and Bloch, Isabelle and Gori, Pietro and Muller, Cecile and Virzi, Alessio and Barbera, Giammarco La},
	year = {2023},
	abbr={PATENT}
}

@article{dufumier_exploring_2024,
	title = {Exploring the potential of representation and transfer learning for anatomical neuroimaging: {Application} to psychiatry},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811924001605},
	doi = {10.1016/j.neuroimage.2024.120665},
	journal = {NeuroImage},
	author = {Dufumier, Benoit and Gori, Pietro and Petiton, Sara and Louiset, Robin and Mangin, Jean-Fran√ßois and Grigis, Antoine and Duchesnay, Edouard},
	year = {2024},
	pages = {120665},
	abbr={NeuroImage}
}

@article{vinit_robotics_2024,
	title = {Robotics and {3D} modeling for precision surgery in pediatric oncology},
	volume = {4},
	url = {https://www.sciencedirect.com/science/article/pii/S2772610X24000412},
	doi = {10.1016/j.ejcped.2024.100181},
	abstract = {In an attempt to minimize surgical trauma in already vulnerable patients, pediatric surgeons are increasingly using minimally invasive surgery in surgical oncology, with similar outcomes as open surgery. In addition to its technical benefits, robotic surgery allows integration of technological enhancements, such as artificial-intelligence-based software or tri-dimensional (3D) modeling, into the operating room. In this article, we report our experience in robotic-assisted surgery for the resection of pediatric tumors and present current developments in 3D modeling applied to pelvic tumors. Since 2016, 149 oncology cases have been undertaken using the robotic approach. Neuroblastic tumors account for the most part, with a median hospital stay of two days [1‚Äì7 days] and very few intraoperative events. The use of robotics was mainly extended to renal tumors (predominantly Wilms tumors) and endocrine tumors, but was found of particular interest for pelvic tumors. Our experience led us to publish a first set of guidelines on robotic surgical oncology, focusing on its apparent contraindications. 3D models derived from preoperative magnetic resonance imaging have been developed for more than 150 patients with solid tumors, but the pelvic area was made a key focus because of its anatomical complexity. In addition to their educational benefits, some of these 3D models were integrated into the robotic console as a surgical aid and proved invaluable for difficult dissections or nerve plexus preservation. As evidenced by the development of robotics and 3D modeling, pediatric oncology is leaning toward ultra-precise surgical resection tailored to the patient and the tumor.},
	journal = {EJC Paediatric Oncology},
	author = {Vinit, Nicolas and Blanc, Thomas and Bloch, Isabelle and Pio, Luca and Kassir, Rani and La Barbera, Giammarco and Bonnot, Enzo and Gori, Pietro and Goulin, Jeanne and Pire, Aurore and Boddaert, Nathalie and Lozach, C√©cile and Sarnacki, Sabine},
	year = {2024},
	pages = {100181},
	abbr={EJC Paediatric Oncology}
}

@inproceedings{laval_towards_2024,
	title = {Towards a foundation model for cortical folding},
	booktitle = {Machine {Learning} in {Clinical} {Neuroimaging} ({MLCN}) {Workshop} - {MICCAI}},
	author = {Laval, Julien and Chavas, Jo√´l and Troiani, Vanessa and Snyder, William and Patti, Marisa and Moyal, Myl√®ne and Plaze, Marion and Cachia, Arnaud and Sun, Zhong Yi and Frouin, Vincent and Gori, Pietro and Rivi√®re, Denis and Mangin, Jean-Fran√ßois},
	year = {2024},
	abbr={MICCAI-W},
	url={https://telecom-paris.hal.science/hal-04675425v1/document}
}

@phdthesis{gori_modeling_2024,
	address = {Paris},
	type = {{HDR} {Thesis}},
	title = {Modeling, {Learning}, and {Transferring} {Anatomical} {Representations} in {Medical} {Imaging} using {AI}},
	school = {Institut Polytechnique de Paris (IPParis)},
	author = {Gori, Pietro},
	year = {2024},
	abbr={HDR}
}

@inproceedings{barbano_unbiased_2023,
	title = {Unbiased {Supervised} {Contrastive} {Learning}},
	abstract = {Many datasets are biased, namely they contain easy-to-learn features that are highly correlated with the target class only in the dataset but not in the true underlying distribution of the data. For this reason, learning unbiased models from biased data has become a very relevant research topic in the last years. In this work, we tackle the problem of learning representations that are robust to biases. We first present a margin-based theoretical framework that allows us to clarify why recent contrastive losses (InfoNCE, SupCon, etc.) can fail when dealing with biased data. Based on that, we derive a novel formulation of the supervised contrastive loss (\${\textbackslash}epsilon\$-SupInfoNCE), providing more accurate control of the minimal distance between positive and negative samples. Furthermore, thanks to our theoretical framework, we also propose FairKL, a new debiasing regularization loss, that works well even with extremely biased data. We validate the proposed losses on standard vision datasets including CIFAR10, CIFAR100, and ImageNet, and we assess the debiasing capability of FairKL with \${\textbackslash}epsilon\$-SupInfoNCE, reaching state-of-the-art performance on a number of biased datasets, including real instances of biases "in the wild".},
	booktitle = {The {Eleventh} {International} {Conference} on {Learning} {Representations} ({ICLR})},
	author = {Barbano, Carlo Alberto and Dufumier, Benoit and Tartaglione, Enzo and Grangetto, Marco and Gori, Pietro},
	year = {2023},
	url = {https://arxiv.org/abs/2211.05568},
	abbr={ICLR},
	code={https://github.com/EIDOSLAB/unbiased-contrastive-learning}
}
