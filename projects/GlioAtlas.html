<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Glioblastoma atlas estimation | Pietro Gori </title> <meta name="author" content="Pietro Gori"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logoTP.png?8ebccf6bd87915c074042a2dc58c272b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pietrogori.github.io/projects/GlioAtlas"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Pietro</span> Gori </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">Team </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Glioblastoma atlas estimation</h1> <p class="post-description"></p> </header> <article> <p><strong>Title</strong> : Glioblastoma atlas estimation<br> <strong>Project coordinator</strong> : Pietro Gori<br> <strong>Participants</strong> : I. Bloch (Télécom Paris), J. Glaunès (MAP5), Catherine Oppenheim (IPNP)<br> <strong>Institutions</strong> : Télécom Paris, Université Paris Cité and St. Anne hospital <br> <strong>Funding</strong>: Future &amp; Rupture PhD Thesis grant (105 k€) + Doctoral School ED386 PhD Thesis grant (105 k€)<br> <strong>Period</strong> : 2019-2023</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Team-Glioma-480.webp 480w,/assets/img/Team-Glioma-800.webp 800w,/assets/img/Team-Glioma-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Team-Glioma.png" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><strong>Context</strong> - Glioblastoma (GBM) is a type of aggressive brain cancer that is still considered incurable and it accounts for more than 60% of all brain tumours in adults <a class="citation" href="#roux_mri_2019">(Roux et al., 2019)</a>. The low survival rate and negative prognosis have fostered a lot of research for a better understanding of the behavior of this kind of tumor. Clinical evidence suggests that tumor size, location, and shape could be important factors related to recurrence and seizures. The standard research protocol to detect brain tumors is Magnetic Resonance Imaging (MRI) as it constitutes a non-ionizing and non-invasive method to produce detailed images of the brain internal structures. Different MRI modalities are usually used as they provide different contrast between tissues, highlighting specific tumor parts. The commonly acquired modalities are T1, T1 contrast-enhanced (T1ce), T2, and Flair. As shown in the figure below, the contrast in each modality is different and each one highlights different tumor regions. For instance, the T1ce image shows the necrotic region and the enhancing tissue, while the Flair and T2 better reveal the edema.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/brats_example-480.webp 480w,/assets/img/brats_example-800.webp 800w,/assets/img/brats_example-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/brats_example.png" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Example of the four MRI modalities commonly used to study brain tumors. Last figure presents the corresponding manual segmentation of the brain glioblastoma. The yellow part is the necrotic tumor, blue is the tumor core, and red is the edema. </div> <p><strong>Goal</strong>: Propose a new method to estimate a 3D statistical atlas of glioblastoma using a population of MR brain images.</p> <p><strong>Challenges</strong>: In medical imaging, a statistical atlas is usually defined as an average image and a set of deformations of the average. The deformations should model the variability within the population. Most of the works in the literature focus on the morphological variability, namely the variations in shape of the anatomical structures. This analysis is relevant for modeling the healthy anatomical variability, as well as pathological variations that only concern the anatomy (e.g., atrophy in Alzheimer’s disease). Most of the works define the deformations as diffeomorphisms, which are differentiable (smooth and continuous) bijective transformation (one-to-one) with differentiable inverse. The main reason is the anatomical plausibility of the produced deformations, since they preserve the topology and spatial organization, namely no intersection, folding or shearing may occur. However, the presence of tumors induce two sources of variation that can not be taken into account by diffeomorphisms: topological and appearance changes. The first is due to the presence of tumors, since two subjects may have a different number of tumors at different locations. Appearance differences are instead due to the infiltration of the tumors causing the edema. This means that previous methods, mainly based on diffeomorphisms or splines deformations, can not be used to estimate a 3D atlas of glioblastoma. <br> To disentangle shape and appearance variations and thus build a clinically relevant and accurate 3D atlas of glioblastoma, it is very important to correctly segment the tumor and the edema in the MR image. Multi-modal segmentation models represent the state-of-the-art technique to detect brain tumors. However, it is often difficult to obtain multiple modalities in a clinical setting due to a limited number of physicians and scanners, and to limit costs and scan time. Most of the time, only one modality is acquired.</p> <p><strong>Contributions</strong> In this project, we proposed three original contributions:</p> <ul> <li>A new framework, called KD-Net, to transfer knowledge from a multi-modal segmentation network (Teacher) to a mono-modal one (Student) <a class="citation" href="#hu_knowledge_2020">(Hu et al., 2020)</a>. The student network produces a precise segmentation of all tumor areas taking as input only images from a single modality. This method can thus be used in a clinical setting, leveraging the rich datasets and computational resources available in research laboratories.</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/architecture-seg-480.webp 480w,/assets/img/architecture-seg-800.webp 800w,/assets/img/architecture-seg-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/architecture-seg.png" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/better_result-480.webp 480w,/assets/img/better_result-800.webp 800w,/assets/img/better_result-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/better_result.png" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Two implementations of the Metamorphosis image registration method based on a new semi-Lagrangian scheme <a class="citation" href="#francois_metamorphic_2021">(François et al., 2021)</a> . The first uses classical numerical integration schemes <a class="citation" href="#francois_weighted_2022">(François et al., 2022)</a> while the second employs a deep learning architecture (i.e., ResNet) <a class="citation" href="#maillard_deep_2022">(Maillard et al., 2022)</a>. Both methods leverage the KD-Net segmentation method to correctly disentangling appearance and morphological variations.</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/architecture-480.webp 480w,/assets/img/architecture-800.webp 800w,/assets/img/architecture-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/architecture.png" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/brats2021_results-480.webp 480w,/assets/img/brats2021_results-800.webp 800w,/assets/img/brats2021_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/brats2021_results.png" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WBIR</abbr> </div> <div id="francois_weighted_2022" class="col-sm-8"> <div class="title">Weighted Metamorphosis for Registration of Images with Different Topologies</div> <div class="author"> Anton François, Matthis Maillard, Catherine Oppenheim, Johan Pallud, Isabelle Bloch, <em>Pietro Gori</em>, and Joan Glaunès </div> <div class="periodical"> <em>In Biomedical Image Registration (WBIR)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1007/978-3-031-11203-4_2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-11203-4_2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/antonfrancois/Demeter_metamorphosis" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We present an extension of the Metamorphosis algorithm to align images with different topologies and/or appearances. We propose to restrict/limit the metamorphic intensity additions using a time-varying spatial weight function. It can be used to model prior knowledge about the topological/appearance changes (e.g., tumour/oedema). We show that our method improves the disentanglement between anatomical (i.e., shape) and topological (i.e., appearance) changes, thus improving the registration interpretability and its clinical usefulness. As clinical application, we validated our method using MR brain tumour images from the BraTS 2021 dataset. We showed that our method can better align healthy brain templates to images with brain tumours than existing state-of-the-art methods. Our PyTorch code is freely available here: https://github.com/antonfrancois/Demeter_metamorphosis.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE ISBI</abbr> </div> <div id="maillard_deep_2022" class="col-sm-8"> <div class="title">A Deep Residual Learning Implementation of Metamorphosis</div> <div class="author"> Matthis Maillard, Anton François, Joan Glaunès, Isabelle Bloch, and <em>Pietro Gori</em> </div> <div class="periodical"> <em>In 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1109/ISBI52829.2022.9761422" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://arxiv.org/pdf/2202.00676" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/mattmail/ResNet_Metamorphoses" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>In medical imaging, most of the image registration methods implicitly assume a one-to-one correspondence between the source and target images (i.e., diffeomorphism). However, this is not necessarily the case when dealing with pathological medical images (e.g., presence of a tumor, lesion, etc.). To cope with this issue, the Metamorphosis model has been proposed. It modifies both the shape and the appearance of an image to deal with the geometrical and topological differences. However, the high computational time and load have hampered its applications so far. Here, we propose a deep residual learning implementation of Metamorphosis that drastically reduces the computational time at inference. Furthermore, we also show that the proposed framework can easily integrate prior knowledge of the localization of topological changes (e.g., segmentation masks) that can act as spatial regularization to correctly disentangle appearance and shape changes. We test our method on the BraTS 2021 dataset, showing that it outperforms current state-of-the-art methods in the alignment of images with brain tumors.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">GSI</abbr> </div> <div id="francois_metamorphic_2021" class="col-sm-8"> <div class="title">Metamorphic Image Registration Using a Semi-lagrangian Scheme</div> <div class="author"> Anton François, <em>Pietro Gori</em>, and Joan Glaunès </div> <div class="periodical"> <em>In Geometric Science of Information</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1007/978-3-030-80209-7_84" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://link.springer.com/chapter/10.1007/978-3-030-80209-7_84" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/antonfrancois/Demeter_metamorphosis" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>In this paper, we propose an implementation of both Large Deformation Diffeomorphic Metric Mapping (LDDMM) and Metamorphosis image registration using a semi-Lagrangian scheme for geodesic shooting. We propose to solve both problems as an inexact matching providing a single and unifying cost function. We demonstrate that for image registration the use of a semi-Lagrangian scheme is more stable than a standard Eulerian scheme. Our GPU implementation is based on PyTorch, which greatly simplifies and accelerates the computations thanks to its powerful automatic differentiation engine. It will be freely available at https://github.com/antonfrancois/Demeter_metamorphosis.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MICCAI</abbr> </div> <div id="hu_knowledge_2020" class="col-sm-8"> <div class="title">Knowledge Distillation from Multi-modal to Mono-modal Segmentation Networks</div> <div class="author"> Minhao Hu, Matthis Maillard, Ya Zhang, Tommaso Ciceri, Giammarco La Barbera, Isabelle Bloch, and <em>Pietro Gori</em> </div> <div class="periodical"> <em>In Medical Image Computing and Computer Assisted Intervention – MICCAI</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1007/978-3-030-59710-8_75" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://link.springer.com/chapter/10.1007/978-3-030-59710-8_75" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>The joint use of multiple imaging modalities for medical image segmentation has been widely studied in recent years. The fusion of information from different modalities has demonstrated to improve the segmentation accuracy, with respect to mono-modal segmentations, in several applications. However, acquiring multiple modalities is usually not possible in a clinical setting due to a limited number of physicians and scanners, and to limit costs and scan time. Most of the time, only one modality is acquired. In this paper, we propose KD-Net, a framework to transfer knowledge from a trained multi-modal network (teacher) to a mono-modal one (student). The proposed method is an adaptation of the generalized distillation framework where the student network is trained on a subset (1 modality) of the teacher’s inputs (n modalities). We illustrate the effectiveness of the proposed framework in brain tumor segmentation with the BraTS 2018 dataset. Using different architectures, we show that the student network effectively learns from the teacher and always outperforms the baseline mono-modal network in terms of segmentation accuracy.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Radiology</abbr> </div> <div id="roux_mri_2019" class="col-sm-8"> <div class="title">MRI Atlas of IDH Wild-Type Supratentorial Glioblastoma: Probabilistic Maps of Phenotype, Management, and Outcomes</div> <div class="author"> Alexandre Roux, Pauline Roca, Myriam Edjlali, Kanako Sato, Marc Zanello, Edouard Dezamis, <em>Pietro Gori</em>, Stéphanie Lion, Ariane Fleury, Frédéric Dhermain, Jean-François Meder, Fabrice Chrétien, Emmanuèle Lechapt, Pascale Varlet, Catherine Oppenheim, and Johan Pallud </div> <div class="periodical"> <em>Radiology</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://doi.org/10.1148/radiol.2019190491" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://pubs.rsna.org/doi/10.1148/radiol.2019190491" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="abstract hidden"> <p>BackgroundTumor location is a main prognostic parameter in patients with glioblastoma. Probabilistic MRI-based brain atlases specifying the probability of tumor location associated with important demographic, clinical, histomolecular, and management data are lacking for isocitrate dehydrogenase (IDH) wild-type glioblastomas.PurposeTo correlate glioblastoma location with clinical phenotype, surgical management, and outcomes by using a probabilistic analysis in a three-dimensional (3D) MRI-based atlas.Materials and MethodsThis retrospective study included all adults surgically treated for newly diagnosed IDH wild-type supratentorial glioblastoma in a tertiary adult surgical neuro-oncology center (2006–2016). Semiautomated tumor segmentation and spatial normalization procedures to build a 3D MRI-based atlas were validated. The authors performed probabilistic analyses by using voxel-based lesion symptom mapping technology. The Liebermeister test was used for binary data, and the generalized linear model was used for continuous data.ResultsA total of 392 patients (mean age, 61 years ± 13; 233 men) were evaluated. The authors identified the preferential location of glioblastomas according to subventricular zone, age, sex, clinical presentation, revised Radiation Therapy Oncology Group-Recursive Partitioning Analysis class, Karnofsky performance status, O6-methylguanine DNA methyltransferase promoter methylation status, surgical management, and survival. The superficial location distant from the eloquent area was more likely associated with a preserved functional status at diagnosis (348 of 392 patients [89%], P \textless .05), a large surgical resection (173 of 392 patients [44%], P \textless .05), and prolonged overall survival (163 of 334 patients [49%], P \textless .05). In contrast, deep location and location within eloquent brain areas were more likely associated with an impaired functional status at diagnosis (44 of 392 patients [11%], P \textless .05), a neurologic deficit (282 of 392 patients [72%], P \textless .05), treatment with biopsy only (183 of 392 patients [47%], P \textless .05), and shortened overall survival (171 of 334 patients [51%], P \textless .05).ConclusionThe authors identified the preferential location of isocitrate dehydrogenase wild-type glioblastomas according to parameters of interest and provided an image-based integration of multimodal information impacting survival results. This suggests the role of glioblastoma location as a surrogate and multimodal parameter integrating several known prognostic factors.© RSNA, 2019Online supplemental material is available for this article.See also the editorial by Huang in this issue.</p> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Pietro Gori. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: March 10, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>