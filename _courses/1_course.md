---
layout: page
title: Representation Learning (MVA)
description:
img: 
importance: 1
related_publications: false
tags: [Machine Learning, Image Processing]
permalink: /teaching/RepLearnMVA
---

**Title**: Representation Learning for Computer Vision and Medical Imaging  

**Instructors**: Pietro Gori and Loïc Le Folgoc  

**Objectives and Topics**: Good and expressive data representations can improve the accuracy of machine learning problems and ease interpretability and transfer. For computer vision and medical imaging tasks, handcrafting good data representations, a.k.a. feature
engineering, was traditionally hard. Deep Learning has changed this paradigm by allowing the automatic discovery of good representations from data. This is known as *representation learning*. The objective of this course is to provide an introduction to representation learning in computer vision and medical imaging applications. We will cover the following topics:    

• Representation Learning  
• Transfer Learning  
• Domain Adaptation  
• Multi-task Learning  
• Knowledge Distillation  
• Self-Supervised Learning and Foundation models  
• Attention and Transformers  
• Disentangled Representations using Generative Models  
• Uncertainty, Interpretability and Explainability in Neural Networks  


**Validation**: Grading will be based on the practical session reports (50%) and written or oral exam (depending on the number of students) (50%).  

**Language**: English or French (depending on the audience)  


**Organization**: 8 lectures divided into 1,5h of theory and 1,5h of practical session + 1 session of exam  

**Location**: All lectures and practical sessions will be held at [Télécom Paris](https://www.telecom-paris.fr/fr/ecole/bref/acces-contact). **Please bring your own laptop** 

**Lectures**:  

| Date | Time | Title | Type | Room | Instructor |  
|---------------|---------------|---------------|  
|13/01/2025|13:30-16:45|Introduction + Transfer Learning|[Cours](https://partage.imt.fr/index.php/s/Pdt9FA9Xgm7J89x) + [TP](https://partage.imt.fr/index.php/s/FnNwsNBYWkcNsn5) + [Intro Pytorch](https://partage.imt.fr/index.php/s/jrny5JYQLnXb8yP) + [Rendu](https://partage.imt.fr/index.php/s/gPTsc4KECjDJDA6)|5B07|P. Gori|  
|20/01/2025|13:30-16:45|Domain Adaptation + Multitask Learning + Knowledge Distillation|[Cours](https://partage.imt.fr/index.php/s/Pdt9FA9Xgm7J89x) + TP|5B07|P. Gori| 
|27/01/2025|13:30-16:45|Self-Supervised Learning 1|[Cours](../assets/pdf/Corso_Self_Supervised.pdf) + TP|5B07|P. Gori| 
|03/02/2025|13:30-16:45|Self-Supervised Learning 2|[Cours](../assets/pdf/Corso_Self_Supervised.pdf) + TP|3A209|P. Gori| 
|10/02/2025|13:30-16:45|Transformers 1|Cours + TP|5B07|L. Le Folgoc| 
|17/02/2025|13:30-16:45|Transformers 2|Cours + TP|5B07|L. Le Folgoc| 
|03/03/2025|13:30-16:45|Uncertainty, Interpretability and Explainability|Cours + TP|3A209|P. Gori|
|10/03/2025|13:30-16:45| Variation AutoEncoders (VAE) and Disentanglement|Cours + TP|3A209|L. Le Folgoc| 
|24/03/2025|13:30-16:45|Exam||3A209|| 


